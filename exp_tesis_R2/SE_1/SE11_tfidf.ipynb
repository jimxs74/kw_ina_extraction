{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r30_lg.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    usulan personil proposed key personnel no tert...\n",
       "1    template document project mengacu ctr exhibit ...\n",
       "2    inquiry usulan lingkup scope aakomodasi ruanga...\n",
       "Name: preprocessed_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess data\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    stopwords_path = os.path.join(repo_root, \"notebooks/stopwords_tuning/all_stop_words.txt\")\n",
    "    with open(stopwords_path, 'r') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "\n",
    "    dictionary = ArrayDictionary(stopwords)\n",
    "    str = StopWordRemover(dictionary)\n",
    "    text = str.remove(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['preprocessed_text'] = df['text'].apply(preprocess)\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(preprocess)\n",
    "text = df['preprocessed_text']\n",
    "\n",
    "#example\n",
    "text.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for sorting tf_idf in descending order\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "        \n",
    "    return results\n",
    "\n",
    "def get_top_phrase(corpus, n=None):\n",
    "    vec1 = CountVectorizer(ngram_range=(2,3),  \n",
    "            max_features=2000).fit([corpus])\n",
    "    bag_of_words = vec1.transform([corpus])\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n",
    "                  vec1.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Initialize CountVectorizer\n",
    "    cv = CountVectorizer(max_df=0.8, max_features=10000, ngram_range=(1, 3))\n",
    "    # Fit and transform the text data to a matrix of token counts\n",
    "    X = cv.fit_transform(text)\n",
    "    # Initialize TfidfTransformer\n",
    "    tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "    # Fit the transformer to the count matrix\n",
    "    tfidf_transformer.fit(X)\n",
    "    # Extract feature names\n",
    "    feature_names = cv.get_feature_names_out()\n",
    "\n",
    "    return feature_names\n",
    "\n",
    "feature_names = process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>score_6</th>\n",
       "      <th>score_7</th>\n",
       "      <th>score_8</th>\n",
       "      <th>score_9</th>\n",
       "      <th>score_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fase tender</td>\n",
       "      <td>diajukan fase tender</td>\n",
       "      <td>diajukan fase</td>\n",
       "      <td>personil</td>\n",
       "      <td>personil pengganti</td>\n",
       "      <td>organisasi</td>\n",
       "      <td>fase</td>\n",
       "      <td>tender</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>processing facilities demikian</td>\n",
       "      <td>facilities demikian acuan</td>\n",
       "      <td>facilities demikian</td>\n",
       "      <td>demikian acuan pengelolaan</td>\n",
       "      <td>demikian acuan</td>\n",
       "      <td>biru processing facilities</td>\n",
       "      <td>biru processing</td>\n",
       "      <td>ctr</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruangan kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>kantor</td>\n",
       "      <td>artikel</td>\n",
       "      <td>appendix</td>\n",
       "      <td>disediakan lokasi</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>lingkup scope</td>\n",
       "      <td>komposisi</td>\n",
       "      <td>scope</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            key_1                 key_2                           key_3  \\\n",
       "0     fase tender  diajukan fase tender                   diajukan fase   \n",
       "1        template              document  processing facilities demikian   \n",
       "2  ruangan kantor               ruangan                          kantor   \n",
       "\n",
       "                       key_4                key_5                       key_6  \\\n",
       "0                   personil   personil pengganti                  organisasi   \n",
       "1  facilities demikian acuan  facilities demikian  demikian acuan pengelolaan   \n",
       "2                    artikel             appendix           disediakan lokasi   \n",
       "\n",
       "            key_7                       key_8            key_9    key_10  \\\n",
       "0            fase                      tender        pengganti  diajukan   \n",
       "1  demikian acuan  biru processing facilities  biru processing       ctr   \n",
       "2   accommodation               lingkup scope        komposisi     scope   \n",
       "\n",
       "   score_1  score_2  score_3  score_4  score_5  score_6  score_7  score_8  \\\n",
       "0     0.32     0.32     0.32     0.31     0.28     0.27     0.24     0.24   \n",
       "1     0.36     0.22     0.20     0.20     0.20     0.20     0.20     0.20   \n",
       "2     0.39     0.34     0.29     0.23     0.20     0.20     0.20     0.19   \n",
       "\n",
       "   score_9  score_10  \n",
       "0     0.21      0.18  \n",
       "1     0.20      0.19  \n",
       "2     0.19      0.17  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(max_df=0.8, max_features=10000, ngram_range=(1, 3))\n",
    "X = cv.fit_transform(text)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(X)\n",
    "\n",
    "# extract from random title\n",
    "feature_names = cv.get_feature_names_out() #sblmnya method ini .get_feature_names() muncul error\n",
    "feature_names\n",
    "\n",
    "#from utils import sort_coo, extract_topn_from_vector\n",
    "n_tfidf = 10\n",
    "predict_tfidf = pd.DataFrame()\n",
    "for index, row in df.iterrows():\n",
    "    doc = row['preprocessed_text']\n",
    "    tf_idf_vector = tfidf_transformer.transform(cv.transform([doc]))\n",
    "    \n",
    "    sorted_items = sort_coo(tf_idf_vector.tocoo())\n",
    "    keywords = extract_topn_from_vector(feature_names,sorted_items, n_tfidf)\n",
    "\n",
    "    keyword_list = pd.DataFrame.from_dict(keywords, orient='index', columns=['score'])\n",
    "    keyword_list.index.name = 'keyword'\n",
    "    keyword_list.reset_index(inplace=True)\n",
    "\n",
    "    a = pd.DataFrame(keyword_list.keyword).T.reset_index(drop=True)\n",
    "    b = pd.DataFrame(keyword_list.score).round(2).T.reset_index(drop=True)\n",
    "    keywords = pd.concat([a, b], axis=1)\n",
    "    predict_tfidf = pd.concat([predict_tfidf, keywords], ignore_index=True)\n",
    "\n",
    "predict_tfidf.columns = ['key_1', 'key_2','key_3', 'key_4', 'key_5','key_6', 'key_7', 'key_8','key_9','key_10','score_1', 'score_2','score_3','score_4', 'score_5','score_6','score_7', 'score_8','score_9','score_10'] \n",
    "predict_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_similarity, eval\n",
    "\n",
    "targets = df[[\"k1\", \"k2\", \"k3\",\"k4\", \"k5\", \"k6\",\"k7\"]].values.tolist()\n",
    "df_targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation TextRank top 10\n",
    "predict_tfidf_list_10 = predict_tfidf[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10']].values.tolist()\n",
    "eval_tfidf_10 = eval(predict_tfidf_list_10, targets, True).round(3)\n",
    "eval_tfidf_10.columns = ['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_tfidf_10 = eval_tfidf_10[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "#eval_tfidf_10.head(3)\n",
    "\n",
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "tfidf_recall_10 = eval_tfidf_10['flex_recall'].mean()\n",
    "tfidf_prec_10 = eval_tfidf_10['flex_prec'].mean()\n",
    "tfidf_f1_10 = 2 * (tfidf_prec_10 * tfidf_recall_10) / (tfidf_prec_10 + tfidf_recall_10)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_10 = pd.DataFrame({'textrank': [tfidf_recall_10, tfidf_prec_10, tfidf_f1_10]}, index=['recall', 'precision', 'F1'])\n",
    "summary_10 = summary_10.round(3)\n",
    "#summary_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation TextRank top 5\n",
    "predict_tfidf_list_5 = predict_tfidf[['key_1','key_2','key_3', 'key_4','key_5']].values.tolist()\n",
    "eval_tfidf_5 = eval(predict_tfidf_list_5, targets, True).round(3)\n",
    "eval_tfidf_5.columns = ['key_1','key_2','key_3', 'key_4','key_5','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_tfidf_5 = eval_tfidf_5[['key_1','key_2','key_3', 'key_4','key_5', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "#eval_tfidf_5.head(3)\n",
    "\n",
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "tfidf_recall_5 = eval_tfidf_5['flex_recall'].mean()\n",
    "tfidf_prec_5 = eval_tfidf_5['flex_prec'].mean()\n",
    "tfidf_f1_5 = 2 * (tfidf_prec_5 * tfidf_recall_5) / (tfidf_prec_5 + tfidf_recall_5)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_5 = pd.DataFrame({'textrank': [tfidf_recall_5, tfidf_prec_5, tfidf_f1_5]}, index=['recall', 'precision', 'F1'])\n",
    "summary_5 = summary_5.round(3)\n",
    "#summary_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.132\n",
       "precision     0.309\n",
       "F1            0.185"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 3\n",
    "predict_tfidf_list_3 = predict_tfidf[['key_1','key_2','key_3']].values.tolist()\n",
    "eval_tfidf_3 = eval(predict_tfidf_list_3, targets, True).round(3)\n",
    "eval_tfidf_3.columns = ['key_1', 'key_2','key_3','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_tfidf_3 = eval_tfidf_3[['key_1', 'key_2','key_3', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "#eval_tfidf_3.head(3)\n",
    "\n",
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "tfidf_recall_3 = eval_tfidf_3['flex_recall'].mean()\n",
    "tfidf_prec_3 = eval_tfidf_3['flex_prec'].mean()\n",
    "tfidf_f1_3 = 2 * (tfidf_prec_3 * tfidf_recall_3) / (tfidf_prec_3 + tfidf_recall_3)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_3 = pd.DataFrame({'textrank': [tfidf_recall_3, tfidf_prec_3, tfidf_f1_3]}, index=['recall', 'precision', 'F1'])\n",
    "summary_3 = summary_3.round(3)\n",
    "summary_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fase tender</td>\n",
       "      <td>diajukan fase tender</td>\n",
       "      <td>diajukan fase</td>\n",
       "      <td>personil</td>\n",
       "      <td>personil pengganti</td>\n",
       "      <td>organisasi</td>\n",
       "      <td>fase</td>\n",
       "      <td>tender</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>...</td>\n",
       "      <td>usulan</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>processing facilities demikian</td>\n",
       "      <td>facilities demikian acuan</td>\n",
       "      <td>facilities demikian</td>\n",
       "      <td>demikian acuan pengelolaan</td>\n",
       "      <td>demikian acuan</td>\n",
       "      <td>biru processing facilities</td>\n",
       "      <td>biru processing</td>\n",
       "      <td>ctr</td>\n",
       "      <td>...</td>\n",
       "      <td>acuan</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruangan kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>kantor</td>\n",
       "      <td>artikel</td>\n",
       "      <td>appendix</td>\n",
       "      <td>disediakan lokasi</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>lingkup scope</td>\n",
       "      <td>komposisi</td>\n",
       "      <td>scope</td>\n",
       "      <td>...</td>\n",
       "      <td>lingkup kerja</td>\n",
       "      <td>akomodasi</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            key_1                 key_2                           key_3  \\\n",
       "0     fase tender  diajukan fase tender                   diajukan fase   \n",
       "1        template              document  processing facilities demikian   \n",
       "2  ruangan kantor               ruangan                          kantor   \n",
       "\n",
       "                       key_4                key_5                       key_6  \\\n",
       "0                   personil   personil pengganti                  organisasi   \n",
       "1  facilities demikian acuan  facilities demikian  demikian acuan pengelolaan   \n",
       "2                    artikel             appendix           disediakan lokasi   \n",
       "\n",
       "            key_7                       key_8            key_9    key_10  ...  \\\n",
       "0            fase                      tender        pengganti  diajukan  ...   \n",
       "1  demikian acuan  biru processing facilities  biru processing       ctr  ...   \n",
       "2   accommodation               lingkup scope        komposisi     scope  ...   \n",
       "\n",
       "               2            3                     4          5    6  \\\n",
       "0         usulan    pengganti                   NaN        NaN  NaN   \n",
       "1          acuan  pengelolaan               dokumen        NaN  NaN   \n",
       "2  lingkup kerja    akomodasi  services for company  exhibit a  NaN   \n",
       "\n",
       "           key_1          key_2          key_3  flex_recall  flex_prec  \n",
       "0       no_match       no_match       no_match        0.000      0.000  \n",
       "1  partial_match  partial_match       no_match        0.286      0.667  \n",
       "2       no_match       no_match  partial_match        0.143      0.333  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_tfidf_10 = pd.concat([predict_tfidf, df_targets, eval_tfidf_10], axis=1)\n",
    "#predict_tfidf_10.head(3)\n",
    "\n",
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_tfidf_5 = pd.concat([predict_tfidf, df_targets, eval_tfidf_5], axis=1)\n",
    "#predict_tfidf_5.head(3)\n",
    "\n",
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_tfidf_3 = pd.concat([predict_tfidf, df_targets, eval_tfidf_3], axis=1)\n",
    "predict_tfidf_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def write_excel(df, sheet_name, filename):\n",
    "    \"\"\"\n",
    "    Writes the given dataframe to an excel file with the given filename and sheet name.\n",
    "    If the sheet already exists in the file, the data in the sheet will be overwritten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "            if sheet_name in writer.book.sheetnames:\n",
    "                # If sheet already exists, remove it\n",
    "                sheet = writer.book[sheet_name]\n",
    "                writer.book.remove(sheet)\n",
    "\n",
    "            # Write the dataframe to the excel file\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to excel file\n",
    "sheet_name_10 = 'SE11_tfidf_10'\n",
    "sheet_name_5 = 'SE11_tfidf_5'\n",
    "sheet_name_3 = 'SE11_tfidf_3'\n",
    "\n",
    "output_file = 'SE11_tfidf.xlsx'\n",
    "write_excel(predict_tfidf_10, sheet_name_10, output_file)\n",
    "write_excel(predict_tfidf_5, sheet_name_5, output_file)\n",
    "write_excel(predict_tfidf_3, sheet_name_3, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kw_ina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
