{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346 unique words/phrases have been saved to unique_words.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_unique_words(excel_file, output_txt_file):\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(excel_file, engine='openpyxl')\n",
    "\n",
    "    # Concatenate all the columns into a single series\n",
    "    all_words = df.apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "\n",
    "    # Split the words/phrases and get the unique ones\n",
    "    unique_words = set()\n",
    "    for sentence in all_words:\n",
    "        unique_words.update(sentence.split())\n",
    "\n",
    "    # Save the unique words to a .txt file\n",
    "    with open(output_txt_file, 'w') as file:\n",
    "        file.write('\\n'.join(unique_words))\n",
    "\n",
    "    print(f\"{len(unique_words)} unique words/phrases have been saved to {output_txt_file}\")\n",
    "\n",
    "# Usage example\n",
    "excel_file = 'foreign_word.xlsx'\n",
    "output_txt_file = 'unique_words.txt'\n",
    "extract_unique_words(excel_file, output_txt_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReTraining and make pkl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_id.postag import PosTag\n",
    "postagger = PosTag() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset_postag_adj.txt' # Find path for datasets\n",
    "sentences, tags = postagger.read_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = postagger.transform_to_dataset(sentences, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postagger.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postagger.save_model('train_tuned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open hasil training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('vectorizer', DictVectorizer()), ('classifier', RandomForestClassifier(n_estimators=15, random_state=2020))], 'verbose': False, 'vectorizer': DictVectorizer(), 'classifier': RandomForestClassifier(n_estimators=15, random_state=2020), 'vectorizer__dtype': <class 'numpy.float64'>, 'vectorizer__separator': '=', 'vectorizer__sort': True, 'vectorizer__sparse': True, 'classifier__bootstrap': True, 'classifier__ccp_alpha': 0.0, 'classifier__class_weight': None, 'classifier__criterion': 'gini', 'classifier__max_depth': None, 'classifier__max_features': 'sqrt', 'classifier__max_leaf_nodes': None, 'classifier__max_samples': None, 'classifier__min_impurity_decrease': 0.0, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__min_weight_fraction_leaf': 0.0, 'classifier__n_estimators': 15, 'classifier__n_jobs': None, 'classifier__oob_score': False, 'classifier__random_state': 2020, 'classifier__verbose': 0, 'classifier__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load data from a .pkl file\n",
    "with open('train_tuned.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "params = data.get_params()\n",
    "print(params)\n",
    "\n",
    "# Save data to a .txt file\n",
    "#with open('output.txt', 'w') as f:\n",
    "#    f.write(str(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "- sudah di lakukan retraining denagn dataset adjusted namun FW masih masuk dalam keyword extraction juga. ada 2 kemungkinan disini tidak berjalan atau filter FW di main code yg tidak berjalan.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kw_ina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
