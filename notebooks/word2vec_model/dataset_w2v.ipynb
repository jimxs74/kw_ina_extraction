{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r30_lg.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [usulan, personil, penting, proposed, key, per...\n",
       "1    [template, document, jtb, gpf, project, mengac...\n",
       "2    [change, inquiry, terkait, usulan, perubahan, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "\n",
    "    return text\n",
    "\n",
    "df_preprocess = df['text'].apply(preprocess)\n",
    "df_preprocess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Combine the tokenized text from 'judul' and 'isi' columns for Word2Vec training\n",
    "combined_text = df_preprocess.tolist()\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=combined_text, vector_size=200, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3805954 ,  0.19502722, -0.04969674, -0.052543  ,  0.6276642 ,\n",
       "       -0.26888612,  0.34123692,  0.6729766 , -0.48455048, -0.07949165,\n",
       "       -0.46155065, -0.5681077 , -0.08227619,  0.21913697, -0.13342686,\n",
       "        0.01275626,  0.04953588, -0.02091675, -0.24995239, -0.7832174 ,\n",
       "       -0.0140854 , -0.15341513,  0.43259844, -0.21324211, -0.08191957,\n",
       "       -0.2850188 , -0.01729772,  0.00750273, -0.24520853, -0.02684724,\n",
       "        0.5310569 ,  0.5091917 ,  0.25019056, -0.16600998,  0.00123054,\n",
       "        0.07833659,  0.23094776,  0.13595912,  0.13039918, -0.39653382,\n",
       "       -0.2139622 ,  0.0718846 , -0.04618865, -0.24046537,  0.20447627,\n",
       "       -0.2740968 ,  0.02208405,  0.13364516,  0.2741228 ,  0.1346074 ,\n",
       "        0.21759163,  0.02268464,  0.11243378, -0.53286135, -0.38485318,\n",
       "       -0.24340096, -0.12109352, -0.4352853 , -0.39904583,  0.07851148,\n",
       "        0.15959558, -0.38711897,  0.05793848,  0.09909549, -0.6065178 ,\n",
       "        0.3283644 , -0.00252021,  0.6984353 , -0.63422984,  0.1896091 ,\n",
       "       -0.10973369, -0.07711679,  0.24507156,  0.14840215,  0.15754907,\n",
       "        0.09811541,  0.40645266, -0.2174578 , -0.57641137,  0.12356384,\n",
       "       -0.289417  , -0.00918182, -0.27333325,  0.7917804 ,  0.03403158,\n",
       "       -0.06240395,  0.24058226,  0.3966071 ,  0.0778269 , -0.14409849,\n",
       "        0.20770362,  0.29523224,  0.5506807 ,  0.5257208 ,  0.7699896 ,\n",
       "        0.4871184 ,  0.4107293 , -0.13899468,  0.10981919,  0.11419756,\n",
       "       -0.36391434,  0.5410309 ,  0.30242065, -0.18734708, -0.34301263,\n",
       "       -0.41923523,  0.2928339 ,  0.31524104, -0.3788107 , -0.6687261 ,\n",
       "       -0.10351118, -0.53311217, -0.6132814 ,  0.05772331,  0.29677153,\n",
       "       -0.02404067,  0.48934025, -1.1239674 , -0.18708667, -0.29325363,\n",
       "       -0.3016652 ,  0.5114352 ,  0.32028893, -0.10005891, -0.12151854,\n",
       "        0.06011524, -0.282211  ,  0.00918197, -0.14997615,  0.31653777,\n",
       "        0.11793575,  0.08389225, -0.06604699, -0.12414737, -0.1395845 ,\n",
       "        0.4606468 ,  0.08373116, -0.32296026, -0.1954001 , -0.49703753,\n",
       "        0.3002749 , -0.52346796, -0.2031539 ,  0.24201141, -0.00510019,\n",
       "        0.36900115, -0.41699663,  0.5281528 ,  0.34987748,  0.31873822,\n",
       "        0.17292598, -0.5940789 ,  0.12075   ,  0.18051174, -0.36264065,\n",
       "        0.661304  ,  0.15846814, -0.08736769, -0.12936531,  0.01704503,\n",
       "        0.3431034 ,  0.26207444, -0.15618785,  0.13788868,  0.17882918,\n",
       "       -0.05036443,  0.07207873, -0.0828596 , -0.35310858, -0.30544946,\n",
       "       -0.56639886, -0.00294175,  0.1557151 , -0.29596987,  0.33369917,\n",
       "        0.35248998, -0.3867212 ,  0.01884836,  0.17588419, -0.06617444,\n",
       "        0.13160805,  0.35264093,  0.34712908, -0.01007207,  0.38365602,\n",
       "        0.02104782, -0.03193468,  0.3214832 ,  0.6389734 , -0.02741011,\n",
       "        0.1916802 ,  0.2490301 , -0.45383143, -0.16475639,  0.20528229,\n",
       "        0.13770331, -0.20408382, -0.27528483,  0.04100093, -0.13421132],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the vector for a sample word to verify the model has been trained\n",
    "sample_word = \"personil\"\n",
    "if sample_word in model.wv:\n",
    "    sample_vector = model.wv[sample_word]\n",
    "    sample_vector[:10]  # Show the first 10 dimensions of the vector\n",
    "else:\n",
    "    sample_vector = \"The word is not in the model's vocabulary.\"\n",
    "sample_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec_model_surat_lg.model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
