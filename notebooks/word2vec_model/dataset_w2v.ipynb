{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r30_lg.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [usulan, personil, penting, proposed, key, per...\n",
       "1    [template, document, jtb, gpf, project, mengac...\n",
       "2    [change, inquiry, terkait, usulan, perubahan, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "    text = text.split()\n",
    "\n",
    "    return text\n",
    "\n",
    "df_preprocess = df['text'].apply(preprocess)\n",
    "df_preprocess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Combine the tokenized text from 'judul' and 'isi' columns for Word2Vec training\n",
    "combined_text = df_preprocess.tolist()\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=combined_text, vector_size=200, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29301992, -0.21053556,  0.09474085, -0.06578132,  0.58762074,\n",
       "       -0.20749418,  0.04658502,  0.6127915 , -0.36693853,  0.07088743,\n",
       "       -0.09747476, -0.5853474 , -0.02607882,  0.27292496, -0.12088301,\n",
       "        0.17536394,  0.19788462,  0.01887199, -0.12445644, -0.8273433 ,\n",
       "        0.28520113, -0.150734  ,  0.25970906, -0.27165663, -0.13289349,\n",
       "       -0.03076282, -0.34035113, -0.10963814, -0.50268996, -0.21767238,\n",
       "        0.8021536 ,  0.14931756,  0.55109   , -0.12387231, -0.0769696 ,\n",
       "       -0.06895958,  0.36246303, -0.14256117, -0.04798238, -0.46314037,\n",
       "       -0.5317222 , -0.06043896,  0.1056262 ,  0.16585974,  0.28732806,\n",
       "       -0.09175546, -0.1440714 , -0.01731697,  0.15625148,  0.24834019,\n",
       "        0.26558793,  0.18306029,  0.05779925, -0.5489578 ,  0.08694011,\n",
       "       -0.54073817, -0.01016743, -0.53936076, -0.38572463,  0.45442557,\n",
       "        0.05905569, -0.25443566, -0.21378002,  0.2529141 , -0.48555684,\n",
       "        0.24832486, -0.03223069,  0.77982175, -0.3431279 ,  0.6011231 ,\n",
       "       -0.1765142 , -0.09073013,  0.55518085,  0.13749678,  0.03764413,\n",
       "       -0.13489047,  0.7124421 , -0.16659756, -0.7404484 , -0.01744894,\n",
       "       -0.31481132, -0.04497404, -0.4099068 ,  0.8003009 , -0.1596607 ,\n",
       "       -0.16429669,  0.06080435,  0.4703038 , -0.03439189, -0.20954867,\n",
       "        0.5107434 ,  0.2880282 ,  0.4352642 ,  0.43259338,  0.63809294,\n",
       "        0.42980868,  0.45555153, -0.15914644,  0.26128042,  0.08974826,\n",
       "       -0.40844786,  0.6471902 ,  0.08455735, -0.20829386, -0.1278876 ,\n",
       "       -0.39327595,  0.41127822,  0.3984368 , -0.38311338, -0.6165719 ,\n",
       "       -0.12290075, -0.43501672, -0.43715203, -0.0146031 ,  0.37743843,\n",
       "        0.01644396,  0.3317597 , -0.81957597, -0.21324223, -0.19151762,\n",
       "       -0.17100583,  0.5994559 ,  0.39486143, -0.07651253,  0.1521214 ,\n",
       "        0.11583768, -0.22375281, -0.13380048, -0.20549746,  0.1920854 ,\n",
       "        0.14242373,  0.08294062, -0.17314929, -0.2991874 , -0.21626636,\n",
       "        0.7221222 , -0.21646535, -0.29457274, -0.16275534, -0.5619512 ,\n",
       "        0.3416266 , -0.33677825, -0.06411168,  0.27553537,  0.29883382,\n",
       "        0.04673076, -0.2469895 ,  0.6174328 ,  0.12745509,  0.30275795,\n",
       "        0.17166924, -0.3256425 ,  0.3328712 , -0.08565965, -0.39658305,\n",
       "        0.6986678 ,  0.27562508, -0.00511327,  0.1593226 , -0.07396353,\n",
       "        0.16280025,  0.31117663, -0.41601667,  0.18673013, -0.21569797,\n",
       "        0.31104127, -0.05276298,  0.0468278 , -0.41025043, -0.40851492,\n",
       "       -0.3235073 ,  0.16163504, -0.08663859, -0.07577657,  0.31691036,\n",
       "        0.08111485, -0.02974315,  0.48585528,  0.5382479 ,  0.0371472 ,\n",
       "        0.02235095,  0.21176286,  0.19575281, -0.09355692,  0.3778031 ,\n",
       "        0.1484488 , -0.05825681,  0.10178958,  0.8036314 ,  0.15612364,\n",
       "        0.23616421,  0.06892422, -0.53726774, -0.14851493,  0.46537945,\n",
       "        0.2732149 ,  0.03556742, -0.44253257, -0.04807359,  0.05618408],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the vector for a sample word to verify the model has been trained\n",
    "sample_word = \"personil\"\n",
    "if sample_word in model.wv:\n",
    "    sample_vector = model.wv[sample_word]\n",
    "    sample_vector[:10]  # Show the first 10 dimensions of the vector\n",
    "else:\n",
    "    sample_vector = \"The word is not in the model's vocabulary.\"\n",
    "sample_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec_model_surat_lg.model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
