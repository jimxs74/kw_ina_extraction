{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mencari kata yg paling sering muncul dalam semua surat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r29.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    usulan personil penting proposed key personnel...\n",
       "1    template document jtb gpf project mengacu kepa...\n",
       "2    change inquiry terkait usulan perubahan lingku...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df_preprocess = df['text'].apply(preprocess)\n",
    "df_preprocess.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word  frequency\n",
      "0            dan       4234\n",
      "1     kontraktor       4191\n",
      "2           yang       3561\n",
      "3          untuk       3048\n",
      "4     perusahaan       2643\n",
      "5         dengan       2433\n",
      "6           atas       2139\n",
      "7            ini       1936\n",
      "8           pada       1898\n",
      "9             di       1753\n",
      "10            no       1616\n",
      "11           jtb       1614\n",
      "12       tanggal       1501\n",
      "13          dari       1435\n",
      "14         dapat       1367\n",
      "15         dalam       1334\n",
      "16      tersebut       1276\n",
      "17         surat       1182\n",
      "18          kami       1168\n",
      "19          oleh       1038\n",
      "20        kepada       1021\n",
      "21          akan        949\n",
      "22        proyek        931\n",
      "23        terima        921\n",
      "24   disampaikan        865\n",
      "25       sebagai        860\n",
      "26      demikian        852\n",
      "27         kasih        829\n",
      "28           hal        799\n",
      "29       terkait        791\n",
      "30         telah        773\n",
      "31         tidak        759\n",
      "32     pekerjaan        742\n",
      "33         bahwa        738\n",
      "34     perhatian        684\n",
      "35     sampaikan        663\n",
      "36        vendor        663\n",
      "37        change        638\n",
      "38            ke        591\n",
      "39            of        589\n",
      "40       bersama        577\n",
      "41           gas        567\n",
      "42        sesuai        543\n",
      "43     melakukan        534\n",
      "44           gpf        530\n",
      "45       berikut        512\n",
      "46       dokumen        511\n",
      "47          agar        502\n",
      "48  kerjasamanya        496\n",
      "49         covid        487\n"
     ]
    }
   ],
   "source": [
    "# Mencari kata yang paling sering muncul\n",
    "from collections import Counter\n",
    "\n",
    "def get_top_words(df_column, m=50, n=300):\n",
    "    '''\n",
    "    fungsi untuk meendapatkan kata yang paling sering muncul, untuk dimasukan sebagai candidate stop word dengan paramater\n",
    "    df_column: kolom yang akan dihitung\n",
    "    m: jumlah kata yang akan diambil\n",
    "    n : frequency minimum kata yang akan diambil\n",
    "    '''\n",
    "    word_counts = Counter()\n",
    "    for text in df_column:\n",
    "        words = text.split()\n",
    "        word_counts.update(words)\n",
    "    top_words = word_counts.most_common(m)\n",
    "    df_top_words = pd.DataFrame(top_words, columns=['word', 'frequency'])\n",
    "    df_top_words = df_top_words[df_top_words['frequency'] >= n].sort_values(by='frequency', ascending=False)\n",
    "\n",
    "    return df_top_words\n",
    "\n",
    "top_keywords = get_top_words(df_preprocess, 50, 300 )\n",
    "print(top_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word  frequency  tfidf_score\n",
      "0            dan       4234     0.044582\n",
      "1     kontraktor       4191     0.045406\n",
      "2           yang       3561     0.045955\n",
      "3          untuk       3048     0.046779\n",
      "4     perusahaan       2643     0.046871\n",
      "5         dengan       2433     0.048519\n",
      "6           atas       2139     0.048885\n",
      "7            ini       1936     0.049709\n",
      "8           pada       1898     0.051906\n",
      "9             di       1753     0.052821\n",
      "10            no       1616     0.053920\n",
      "11           jtb       1614     0.054103\n",
      "12       tanggal       1501     0.058405\n",
      "13          dari       1435     0.060694\n",
      "14         dapat       1367     0.060694\n",
      "15         dalam       1334     0.062617\n",
      "16      tersebut       1276     0.067560\n",
      "17         surat       1182     0.067926\n",
      "18          kami       1168     0.069482\n",
      "19          oleh       1038     0.070764\n",
      "20        kepada       1021     0.072412\n",
      "21          akan        949     0.073144\n",
      "22        proyek        931     0.075890\n",
      "23        terima        921     0.077996\n",
      "24   disampaikan        865     0.078728\n",
      "25       sebagai        860     0.079186\n",
      "26      demikian        852     0.084313\n",
      "27         kasih        829     0.085228\n",
      "28           hal        799     0.086876\n",
      "29       terkait        791     0.093467\n",
      "30         telah        773     0.095023\n",
      "31         tidak        759     0.106924\n",
      "32     pekerjaan        742     0.108206\n",
      "33         bahwa        738     0.116811\n",
      "34     perhatian        684     0.122120\n",
      "35     sampaikan        663     0.125141\n",
      "36        vendor        663     0.131366\n",
      "37        change        638     0.137408\n",
      "38            ke        591     0.147753\n",
      "39            of        589     0.147936\n",
      "40       bersama        577     0.160478\n",
      "41           gas        567     0.173752\n",
      "42        sesuai        543     0.177230\n",
      "43     melakukan        534     0.195814\n",
      "44           gpf        530     0.222728\n",
      "45       berikut        512     0.241952\n",
      "46       dokumen        511     0.279028\n",
      "47          agar        502     0.325990\n",
      "48  kerjasamanya        496     0.383663\n",
      "49         covid        487     0.387600\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_tfidf_score(df, top_keywords):\n",
    "    '''\n",
    "    Function to calculate the TF-IDF score for the top_keywords\n",
    "    df: the input dataframe\n",
    "    top_keywords: a dataframe containing the top keywords and their frequency\n",
    "    '''\n",
    "    text = df.str.cat(sep=' ')\n",
    "    tfidf_vectorizer = TfidfVectorizer(vocabulary=top_keywords['word'].tolist(), smooth_idf=True, use_idf=True)\n",
    "    tfidf = tfidf_vectorizer.fit_transform([text])\n",
    "    tfidf_scores = dict(zip(tfidf_vectorizer.get_feature_names_out(), tfidf.data))\n",
    "    top_keywords['tfidf_score'] = top_keywords['word'].apply(lambda x: tfidf_scores[x] if x in tfidf_scores else 0)\n",
    "    return top_keywords.sort_values(by='tfidf_score', ascending=True)[:50]\n",
    "\n",
    "# Example usage:\n",
    "top_keywords = get_top_words(df_preprocess, 50, 300)\n",
    "tfidf_scores = get_tfidf_score(df_preprocess, top_keywords)\n",
    "print(tfidf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores[[\"word\"]].to_csv(\"candidate_stopword.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word       tfidf\n",
      "0          covid   33.130793\n",
      "1      melakukan   40.899210\n",
      "2        berikut   44.613363\n",
      "3         sesuai   45.352822\n",
      "4           agar   46.234510\n",
      "5          tidak   49.757862\n",
      "6   kerjasamanya   50.547921\n",
      "7             ke   51.562680\n",
      "8        dokumen   53.301108\n",
      "9            gpf   56.539551\n",
      "10         telah   57.213537\n",
      "11         bahwa   58.890416\n",
      "12     perhatian   59.889230\n",
      "13           hal   60.267971\n",
      "14           gas   60.806016\n",
      "15     pekerjaan   62.393674\n",
      "16       bersama   63.758835\n",
      "17        change   63.865454\n",
      "18         kasih   64.758205\n",
      "19        vendor   65.612570\n",
      "20      demikian   65.654323\n",
      "21            of   66.920863\n",
      "22       sebagai   67.648204\n",
      "23       terkait   69.378713\n",
      "24        terima   70.134076\n",
      "25        kepada   71.337403\n",
      "26          oleh   72.049376\n",
      "27     sampaikan   72.919475\n",
      "28   disampaikan   78.368209\n",
      "29          akan   78.874276\n",
      "30        proyek   85.509612\n",
      "31      tersebut   87.705177\n",
      "32         dapat   89.941874\n",
      "33         surat   89.998653\n",
      "34         dalam   91.315709\n",
      "35          dari   93.112489\n",
      "36            di  101.686998\n",
      "37       tanggal  101.846743\n",
      "38          kami  105.469081\n",
      "39           ini  113.151816\n",
      "40          pada  113.699923\n",
      "41            no  115.874197\n",
      "42          atas  117.305081\n",
      "43           jtb  122.957068\n",
      "44        dengan  139.321604\n",
      "45    perusahaan  147.373340\n",
      "46         untuk  162.501252\n",
      "47          yang  166.970299\n",
      "48    kontraktor  199.945310\n",
      "49           dan  201.387670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "def get_tfidf_top_words(df_column, m=50, n=400):\n",
    "    '''\n",
    "    Fungsi untuk mendapatkan kata yang paling sering muncul,\n",
    "    untuk dimasukkan sebagai candidate stop word dengan parameter:\n",
    "    df_column: kolom yang akan dihitung\n",
    "    m: jumlah kata yang akan diambil\n",
    "    n: frekuensi minimum untuk suatu kata untuk dianggap sebagai candidate stop word\n",
    "    '''\n",
    "    word_counts = Counter()\n",
    "    for text in df_column:\n",
    "        words = text.split()\n",
    "        word_counts.update(words)\n",
    "    top_words = word_counts.most_common(m)\n",
    "    df_top_words = pd.DataFrame(top_words, columns=['word', 'frequency'])\n",
    "    df_top_words = df_top_words[df_top_words['frequency'] >= n].sort_values(by='frequency', ascending=False)\n",
    "    \n",
    "    # Get only the top keywords\n",
    "    keywords = df_top_words['word'].tolist()\n",
    "\n",
    "    # Create a new dataframe to store the tfidf scores\n",
    "    tfidf_df = pd.DataFrame(columns=['word', 'tfidf'])\n",
    "    \n",
    "    # Create a TfidfVectorizer object and fit on the corpus\n",
    "    vectorizer = TfidfVectorizer(vocabulary=keywords, use_idf=True)\n",
    "    X = vectorizer.fit_transform(df_column)\n",
    "\n",
    "    # Compute the tfidf score for each keyword\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        tfidf_score = X[:, vectorizer.vocabulary_[keyword]].toarray().sum()\n",
    "        tfidf_df.loc[i] = [keyword, tfidf_score]\n",
    "        \n",
    "    # Sort by the tfidf score in ascending order\n",
    "    tfidf_df = tfidf_df.sort_values(by='tfidf', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # Return the top 50 words with the lowest tfidf score\n",
    "    return tfidf_df.head(50)\n",
    "\n",
    "tfidf_top_words = get_tfidf_top_words(df_preprocess, 50, 300)\n",
    "print(tfidf_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               word     tfidf\n",
      "0                aa  0.000444\n",
      "1               aae  0.000444\n",
      "2        aakomodasi  0.000444\n",
      "3                ab  0.000444\n",
      "4               abb  0.000444\n",
      "5       abdurrahman  0.000444\n",
      "6             about  0.000444\n",
      "7               abs  0.000444\n",
      "8           absensi  0.000444\n",
      "9         absorbent  0.000444\n",
      "10              abu  0.000444\n",
      "11              acc  0.000444\n",
      "12       accentance  0.000444\n",
      "13         accepted  0.000444\n",
      "14   accomplishment  0.000444\n",
      "15       accordance  0.000444\n",
      "16              acd  0.000444\n",
      "17           achmad  0.000444\n",
      "18        acitivity  0.000444\n",
      "19  acknowledgement  0.000444\n",
      "20              acs  0.000444\n",
      "21           adajan  0.000444\n",
      "22           adakan  0.000444\n",
      "23         adaptasi  0.000444\n",
      "24        addiional  0.000444\n",
      "25          adhered  0.000444\n",
      "26       adisasmito  0.000444\n",
      "27           adityo  0.000444\n",
      "28       administer  0.000444\n",
      "29      adminitrasi  0.000444\n",
      "30         adrianto  0.000444\n",
      "31          adverse  0.000444\n",
      "32         advisors  0.000444\n",
      "33               ae  0.000444\n",
      "34          aerated  0.000444\n",
      "35               af  0.000444\n",
      "36           afrika  0.000444\n",
      "37          against  0.000444\n",
      "38             agak  0.000444\n",
      "39             agen  0.000444\n",
      "40            agent  0.000444\n",
      "41             agxf  0.000444\n",
      "42              ahu  0.000444\n",
      "43              aid  0.000444\n",
      "44             aifa  0.000444\n",
      "45              aju  0.000444\n",
      "46              akb  0.000444\n",
      "47          akhgmya  0.000444\n",
      "48       akitivitas  0.000444\n",
      "49       akreditasi  0.000444\n"
     ]
    }
   ],
   "source": [
    "# Mencari kata dg score TFIDF paling kecil\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "# Combine multiple rows into a single text\n",
    "text = df_preprocess.str.cat(sep=' ')\n",
    "\n",
    "\n",
    "cv = CountVectorizer(max_df=0.8, max_features=10000, ngram_range=(1, 1))\n",
    "X = cv.fit_transform(df_preprocess)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "tfidf_transformer.fit(X)\n",
    "\n",
    "# extract from random title\n",
    "feature_names = cv.get_feature_names_out() #sblmnya method ini .get_feature_names() muncul error\n",
    "n_minimum = 50\n",
    "\n",
    "predict_tfidf = pd.DataFrame()\n",
    "\n",
    "tf_idf_vector = tfidf_transformer.transform(cv.transform([text]))\n",
    "\n",
    "# create a dictionary with feature names and corresponding tf-idf scores\n",
    "feature_tfidf_scores = {}\n",
    "for feature, score in zip(feature_names, tf_idf_vector.toarray()[0]):\n",
    "    feature_tfidf_scores[feature] = score\n",
    "\n",
    "# sort the dictionary by value in ascending order and take the first n_minimum items\n",
    "sorted_tfidf_scores = sorted(feature_tfidf_scores.items(), key=lambda x: x[1])\n",
    "top_words = sorted_tfidf_scores[:n_minimum]\n",
    "\n",
    "# create a DataFrame with the top words and their tf-idf scores\n",
    "df_top_words = pd.DataFrame(top_words, columns=['word', 'tfidf'])\n",
    "print(df_top_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINED STOPWORDS\n",
    "Tala + Sastrawi + Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    stopwords_path = os.path.join(repo_root, \"data/all_stop_words.txt\")\n",
    "    with open(stopwords_path, 'r') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "\n",
    "    dictionary = ArrayDictionary(stopwords)\n",
    "    str = StopWordRemover(dictionary)\n",
    "    text = str.remove(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory, StopWordRemover, ArrayDictionary\n",
    "\n",
    "# ambil list stopword sastrawi\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "stopword_sastrawi = stop_factory.get_stop_words()\n",
    "\n",
    "# ambil list stopword Tala\n",
    "with open('stopword_list_tala.txt', 'r') as f:\n",
    "    stopword_tala = [line.strip() for line in f]\n",
    "\n",
    "# ambil list stopword candidate corpus skrg  \n",
    "with open('candidate_stopword.txt', 'r') as f:\n",
    "    stopword_corpus = [line.strip() for line in f]\n",
    "\n",
    "stop_words = stopword_sastrawi + stopword_tala + stopword_corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_stop_words.txt', 'w') as f:\n",
    "    f.write('\\n'.join(stop_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
