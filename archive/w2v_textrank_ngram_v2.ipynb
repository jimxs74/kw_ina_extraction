{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine PKE textrank and word2vec N-gram\n",
    "\n",
    "V1 Feature\n",
    "- Membuat jalan program\n",
    "- Ada deteksi unigram/bigram/trigram\n",
    "\n",
    "V2\n",
    "- filter jika kata tidak ada dalam model embedding w2v\n",
    "- implementasi stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"notebooks/postager_nlp-id/dataset_ekstraksi_r29_pos_sm.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]\n",
    "#df_pos = df['pos_sentence_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemover, ArrayDictionary\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    stopwords_path = os.path.join(repo_root, \"data/all_stop_words.txt\")\n",
    "    with open(stopwords_path, 'r') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "\n",
    "    dictionary = ArrayDictionary(stopwords)\n",
    "    str = StopWordRemover(dictionary)\n",
    "    text = str.remove(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['preprocessed_text'] = df['text'].apply(preprocess)\n",
    "df_tr = df['preprocessed_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def generate_ngrams(words, n=2):\n",
    "    \"\"\"Generate ngrams from a list of words.\"\"\"\n",
    "    return [\" \".join(gram) for gram in ngrams(words, n)]\n",
    "\n",
    "def get_phrase_embedding(phrase, w2v_model):\n",
    "    \"\"\"Get the averaged word embedding for a phrase.\"\"\"\n",
    "    words = phrase.split()\n",
    "    embeddings = [w2v_model.wv[word] for word in words if word in w2v_model.wv.key_to_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def extract_keyphrases_with_ngrams(text, w2v_model, n=3):\n",
    "    # Read stopwords from the file\n",
    "    stopwords_path = os.path.join(repo_root, \"data/all_stop_words.txt\")\n",
    "    with open(stopwords_path, 'r') as file:\n",
    "        stopwords = set(file.read().strip().splitlines())\n",
    "\n",
    "    # Tokenize the text into unigrams\n",
    "    pre_unigrams = text.split()\n",
    "    unigrams = [word for word in text.split() if word not in stopwords]\n",
    "    \n",
    "    # Generate bigrams and trigrams\n",
    "    bigrams = generate_ngrams(pre_unigrams, 2)\n",
    "    trigrams = generate_ngrams(pre_unigrams, 3)\n",
    "\n",
    "    # Count occurrences of bigrams and trigrams\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    trigram_counts = Counter(trigrams)\n",
    "\n",
    "    # Filter bigrams and trigrams that appear more than 2 times\n",
    "    bigrams = [bigram for bigram in bigrams if bigram_counts[bigram] > 2]\n",
    "    trigrams = [trigram for trigram in trigrams if trigram_counts[trigram] > 2]\n",
    "\n",
    "    # Combine unigrams, filtered bigrams, and filtered trigrams\n",
    "    all_tokens = unigrams + bigrams + trigrams\n",
    "    \n",
    "    # Get embeddings for each token (averaging word embeddings for bigrams/trigrams)\n",
    "    token_embeddings = [get_phrase_embedding(token, w2v_model) for token in all_tokens]\n",
    "    \n",
    "    # Filter out tokens that don't have embeddings\n",
    "    tokens, embeddings = zip(*[(token, emb) for token, emb in zip(all_tokens, token_embeddings) if emb is not None])\n",
    "    \n",
    "    # Compute the cosine similarity between token embeddings\n",
    "    cosine_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # Create a graph and connect tokens with high similarity\n",
    "    G = nx.Graph()\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens)):\n",
    "            if cosine_matrix[i][j] > 0.5:  # This threshold can be adjusted\n",
    "                G.add_edge(tokens[i], tokens[j], weight=cosine_matrix[i][j])\n",
    "    \n",
    "    # Compute the PageRank scores to rank the tokens\n",
    "    scores = nx.pagerank(G)\n",
    "\n",
    "    # Extract top N keyphrases along with their scores\n",
    "    ranked_tokens = sorted(((scores[token], token) for token in tokens if token in scores), reverse=True)\n",
    "    keyphrases_with_scores = [(token, score) for score, token in ranked_tokens[:n]]\n",
    "\n",
    "    return keyphrases_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_path = os.path.join(repo_root, \"models/w2v/idwiki_word2vec_100_new_lower.model\")\n",
    "w2v_model = Word2Vec.load(w2v_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Izin Mendirikan Bangunan \"Bangunan Pioneer\" - GPF Project\\n(Construction Permit for \"Pioneer Building\" - GPF Project). Terlampir kami sampaikan surat lzin\\nMendirikan Bangunan No. 410 Tahun 2017\\nyang diterbitkan oleh Dinas Penanaman\\nModal dan Pelayanan Terpadu Satu Pintu\\nKab: Bojonegoro pada tanggal 29 Desember\\n2017, sebagai referensi terkait dengan\\npelaksanaan pekerjaan.\\nDemikian disampaikan, terima kasih atas\\nperhatiannya.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"text\"][i]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('referensi', 0.5), ('diterbitkan', 0.5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrases = extract_keyphrases_with_ngrams(text, w2v_model, 3)\n",
    "keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yang diajukan</td>\n",
       "      <td>yang diajukan</td>\n",
       "      <td>yang diajukan</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perhatiannya</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>acuan</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruangan kantor</td>\n",
       "      <td>ruangan kantor</td>\n",
       "      <td>ruangan kantor</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nya</td>\n",
       "      <td>inspeksi</td>\n",
       "      <td>fungsi</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tanggai</td>\n",
       "      <td>kunjungan</td>\n",
       "      <td>dilaksanakan</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>conduct</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>solusi yang</td>\n",
       "      <td>solusi yang</td>\n",
       "      <td>solusi yang</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>memperhatikan</td>\n",
       "      <td>menyetujui</td>\n",
       "      <td>memenuhi</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>memenuhi</td>\n",
       "      <td>memenuhi</td>\n",
       "      <td>memperhatikan</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>regarding</td>\n",
       "      <td>memperhatikan</td>\n",
       "      <td>on</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sistem EDOCS</td>\n",
       "      <td>sistem EDOCS</td>\n",
       "      <td>sistem EDOCS</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>konfirmasi</td>\n",
       "      <td>konfirmasi</td>\n",
       "      <td>tertulis</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>password</td>\n",
       "      <td>user</td>\n",
       "      <td>user</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>konsorsium</td>\n",
       "      <td>ditindaklanjuti</td>\n",
       "      <td>diterbitkannya</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lahan</td>\n",
       "      <td>lahan</td>\n",
       "      <td>penyerahan</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tanah</td>\n",
       "      <td>tanah</td>\n",
       "      <td>survey</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lampiran</td>\n",
       "      <td>lampiran</td>\n",
       "      <td>gambar</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pipeline</td>\n",
       "      <td>jaringan</td>\n",
       "      <td>pemasangan</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>storage</td>\n",
       "      <td>storage</td>\n",
       "      <td>penggunaan</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>up</td>\n",
       "      <td>target</td>\n",
       "      <td>serah</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lanjuti</td>\n",
       "      <td>mencantumkan</td>\n",
       "      <td>to</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>melaksanakan</td>\n",
       "      <td>materi</td>\n",
       "      <td>materi</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>opsi</td>\n",
       "      <td>biaya</td>\n",
       "      <td>the</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>diterima oleh PERUSAHAAN</td>\n",
       "      <td>diterima oleh PERUSAHAAN</td>\n",
       "      <td>diterima oleh PERUSAHAAN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dilapangan</td>\n",
       "      <td>tim</td>\n",
       "      <td>significant</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ditandatangani</td>\n",
       "      <td>kelancaran</td>\n",
       "      <td>signifikan</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>referensi</td>\n",
       "      <td>diterbitkan</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mengikuti</td>\n",
       "      <td>selesai</td>\n",
       "      <td>tindak</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pedoman</td>\n",
       "      <td>penyusunan</td>\n",
       "      <td>penomoran</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>menerima</td>\n",
       "      <td>mendukung</td>\n",
       "      <td>serah</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       key_1                     key_2  \\\n",
       "0              yang diajukan             yang diajukan   \n",
       "1               perhatiannya               pengelolaan   \n",
       "2             ruangan kantor            ruangan kantor   \n",
       "3                        nya                  inspeksi   \n",
       "4                    tanggai                 kunjungan   \n",
       "5                    conduct                        to   \n",
       "6                solusi yang               solusi yang   \n",
       "7              memperhatikan                menyetujui   \n",
       "8                   memenuhi                  memenuhi   \n",
       "9                  regarding             memperhatikan   \n",
       "10              sistem EDOCS              sistem EDOCS   \n",
       "11                konfirmasi                konfirmasi   \n",
       "12                  password                      user   \n",
       "13                konsorsium           ditindaklanjuti   \n",
       "14                     lahan                     lahan   \n",
       "15                     tanah                     tanah   \n",
       "16                  lampiran                  lampiran   \n",
       "17                  pipeline                  jaringan   \n",
       "18                   storage                   storage   \n",
       "19                        up                    target   \n",
       "20                   lanjuti              mencantumkan   \n",
       "21              melaksanakan                    materi   \n",
       "22                      opsi                     biaya   \n",
       "23  diterima oleh PERUSAHAAN  diterima oleh PERUSAHAAN   \n",
       "24                dilapangan                       tim   \n",
       "25            ditandatangani                kelancaran   \n",
       "26                 referensi               diterbitkan   \n",
       "27                 mengikuti                   selesai   \n",
       "28                   pedoman                penyusunan   \n",
       "29                  menerima                 mendukung   \n",
       "\n",
       "                       key_3  score_1  score_2  score_3  \n",
       "0              yang diajukan    0.028    0.028    0.028  \n",
       "1                      acuan    0.333    0.333    0.333  \n",
       "2             ruangan kantor    0.040    0.040    0.040  \n",
       "3                     fungsi    0.167    0.167    0.167  \n",
       "4               dilaksanakan    0.250    0.250    0.250  \n",
       "5                        the    0.167    0.167    0.167  \n",
       "6                solusi yang    0.039    0.039    0.039  \n",
       "7                   memenuhi    0.058    0.041    0.040  \n",
       "8              memperhatikan    0.043    0.043    0.039  \n",
       "9                         on    0.040    0.036    0.036  \n",
       "10              sistem EDOCS    0.029    0.029    0.029  \n",
       "11                  tertulis    0.053    0.053    0.053  \n",
       "12                      user    0.048    0.040    0.040  \n",
       "13            diterbitkannya    0.333    0.333    0.333  \n",
       "14                penyerahan    0.071    0.071    0.071  \n",
       "15                    survey    0.100    0.100    0.100  \n",
       "16                    gambar    0.055    0.055    0.045  \n",
       "17                pemasangan    0.047    0.047    0.047  \n",
       "18                penggunaan    0.040    0.040    0.038  \n",
       "19                     serah    0.111    0.111    0.111  \n",
       "20                        to    0.071    0.071    0.071  \n",
       "21                    materi    0.060    0.057    0.057  \n",
       "22                       the    0.110    0.110    0.100  \n",
       "23  diterima oleh PERUSAHAAN    0.047    0.047    0.047  \n",
       "24               significant    0.050    0.050    0.050  \n",
       "25                signifikan    0.062    0.062    0.053  \n",
       "26                       0.5    0.500    0.000    0.000  \n",
       "27                    tindak    0.065    0.056    0.056  \n",
       "28                 penomoran    0.227    0.219    0.200  \n",
       "29                     serah    0.071    0.070    0.059  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_textrank = pd.DataFrame()\n",
    "for i in df_tr.index:\n",
    "    text = df[\"text\"][i] # sblm di preprocess\n",
    "    #text = df_tr[i] # setelah di preprocess\n",
    "    keyphrases = extract_keyphrases_with_ngrams(text, w2v_model, 3)\n",
    "    df_keyphrases = pd.DataFrame(keyphrases, columns=['Keyword', 'Score'])\n",
    "    a = pd.DataFrame(df_keyphrases.Keyword).T.reset_index(drop=True)\n",
    "    b = pd.DataFrame(df_keyphrases.Score).round(3).T.reset_index(drop=True)\n",
    "    df_keyphrases = pd.concat([a, b], axis=1)\n",
    "\n",
    "    # Check if there are missing columns and add them with zero values\n",
    "    missing_columns = 6 - df_keyphrases.shape[1]\n",
    "    for _ in range(missing_columns):\n",
    "        df_keyphrases[df_keyphrases.shape[1]] = 0\n",
    "\n",
    "    df_keyphrases.columns = ['key_1', 'key_2','key_3','score_1', 'score_2','score_3']\n",
    "    predict_textrank = pd.concat([predict_textrank, df_keyphrases], ignore_index=True)\n",
    "predict_textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval\n",
    "\n",
    "targets = df[[\"k1\", \"k2\", \"k3\",\"k4\", \"k5\", \"k6\",\"k7\"]].values.tolist()\n",
    "df_targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1     key_2     key_3  flex_recall  flex_prec\n",
       "0  no_match  no_match  no_match          0.0        0.0\n",
       "1  no_match  no_match  no_match          0.0        0.0\n",
       "2  no_match  no_match  no_match          0.0        0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank\n",
    "predict_textrank_list = predict_textrank[['key_1','key_2','key_3']].values.tolist()\n",
    "eval_textrank = eval(predict_textrank_list, targets, True).round(3)\n",
    "eval_textrank.columns = ['key_1', 'key_2','key_3','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank = eval_textrank[['key_1', 'key_2','key_3', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.005\n",
       "precision     0.011\n",
       "F1            0.007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall = eval_textrank['flex_recall'].mean()\n",
    "textrank_prec = eval_textrank['flex_prec'].mean()\n",
    "textrank_f1 = 2 * (textrank_prec * textrank_recall) / (textrank_prec + textrank_recall)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary = pd.DataFrame({'textrank': [textrank_recall, textrank_prec, textrank_f1]}, index=['recall', 'precision', 'F1'])\n",
    "summary = summary.round(3)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yang diajukan pada</td>\n",
       "      <td>yang diajukan pada</td>\n",
       "      <td>yang diajukan pada</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>persetujuan tertulis</td>\n",
       "      <td>prosedur</td>\n",
       "      <td>usulan</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sampaikan</td>\n",
       "      <td>ucapkan</td>\n",
       "      <td>yang</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.071</td>\n",
       "      <td>template document</td>\n",
       "      <td>exhibit c</td>\n",
       "      <td>acuan</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dan</td>\n",
       "      <td>dan</td>\n",
       "      <td>dan</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>ruang kantor</td>\n",
       "      <td>change inquiry</td>\n",
       "      <td>lingkup kerja</td>\n",
       "      <td>akomodasi</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                key_1               key_2               key_3  score_1  \\\n",
       "0  yang diajukan pada  yang diajukan pada  yang diajukan pada    0.022   \n",
       "1           sampaikan             ucapkan                yang    0.074   \n",
       "2                 dan                 dan                 dan    0.022   \n",
       "\n",
       "   score_2  score_3                     0               1              2  \\\n",
       "0    0.022    0.022  persetujuan tertulis        prosedur         usulan   \n",
       "1    0.072    0.071     template document       exhibit c          acuan   \n",
       "2    0.022    0.022          ruang kantor  change inquiry  lingkup kerja   \n",
       "\n",
       "             3                     4          5   6     key_1     key_2  \\\n",
       "0    pengganti                   NaN        NaN NaN  no_match  no_match   \n",
       "1  pengelolaan               dokumen        NaN NaN  no_match  no_match   \n",
       "2    akomodasi  services for company  exhibit a NaN  no_match  no_match   \n",
       "\n",
       "      key_3  flex_recall  flex_prec  \n",
       "0  no_match          0.0        0.0  \n",
       "1  no_match          0.0        0.0  \n",
       "2  no_match          0.0        0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank = pd.concat([predict_textrank, df_targets, eval_textrank], axis=1)\n",
    "predict_textrank.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jim/Documents/GitHub/kw_ina_extraction/utils/ia_file_operation.py:15: FutureWarning: Setting the `book` attribute is not part of the public API, usage can give unexpected or corrupted results and will be removed in a future version\n",
      "  writer.book = book\n",
      "/Users/jim/Documents/GitHub/kw_ina_extraction/utils/ia_file_operation.py:24: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "# Write predictions to excel file\n",
    "'''\n",
    "from utils import write_excel\n",
    "\n",
    "sheet_name = 'w2v_tr_phrase'\n",
    "output_file = 'w2v_textrank_ngram_v2.xlsx'\n",
    "write_excel(predict_textrank, sheet_name, output_file)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kw_ina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
