{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r30_lg.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Preprocess\n",
    "import re\n",
    "'''\n",
    "stopwords tidak masuk dalam preprocessing\n",
    "'''\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df['text'].apply(preprocess)\n",
    "df[\"judul\"] = df[\"judul\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Load stopword\n",
    "stopwords_path = os.path.join(repo_root, \"notebooks/stopwords_tuning/all_stop_words.txt\")\n",
    "with open(stopwords_path, 'r') as file:\n",
    "    stopwords = set(file.read().strip().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Phrase Detection\n",
    "\n",
    "from collections import Counter\n",
    "from nlp_id_local.tokenizer import PhraseTokenizer \n",
    "from nlp_id_local.postag import PosTag\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def generate_ngrams(words, n=2):\n",
    "    \"\"\"Generate ngrams from a list of words.\"\"\"\n",
    "    return [\" \".join(gram) for gram in ngrams(words, n)]\n",
    "\n",
    "def detect_bigram(text):\n",
    "    \n",
    "    tokenizer = PhraseTokenizer()\n",
    "    phrases = tokenizer.tokenize(text)\n",
    "    # Include only bigrams whose individual words are in available_tokens\n",
    "    bigrams_only = [phrase for phrase in phrases if phrase.count(\" \") == 1]\n",
    "\n",
    "    return bigrams_only\n",
    "\n",
    "def detect_trigram(text):\n",
    "\n",
    "    tokenizer = PhraseTokenizer()\n",
    "    phrases = tokenizer.tokenize(text)\n",
    "    # Include only trigrams whose individual words are in available_tokens\n",
    "    trigrams_only = [phrase for phrase in phrases if phrase.count(\" \") == 2 ]\n",
    "\n",
    "    return trigrams_only\n",
    "\n",
    "# Function to incorporate bigrams and trigrams in the correct sequence\n",
    "def incorporate_bigrams_trigrams(unigrams, bigrams, trigrams):\n",
    "    combined_tokens = []\n",
    "    skip = 0\n",
    "\n",
    "    for i in range(len(unigrams)):\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "\n",
    "        bigram_formed = ' '.join(unigrams[i:i+2]) in bigrams\n",
    "        trigram_formed = ' '.join(unigrams[i:i+3]) in trigrams\n",
    "\n",
    "        if bigram_formed:\n",
    "            combined_tokens.append(' '.join(unigrams[i:i+2]))\n",
    "            skip = 1\n",
    "        elif trigram_formed:\n",
    "            combined_tokens.append(' '.join(unigrams[i:i+3]))\n",
    "            skip = 2\n",
    "        else:\n",
    "            combined_tokens.append(unigrams[i])\n",
    "\n",
    "    return combined_tokens\n",
    "\n",
    "def detect_all_tokens(text):\n",
    "    unigrams = [word for word in text.split()]\n",
    "    bigrams = detect_bigram(text)\n",
    "    trigrams = detect_trigram(text)\n",
    "    \n",
    "    # Incorporating bigrams and trigrams into the sequence of tokens\n",
    "    all_tokens = incorporate_bigrams_trigrams(unigrams, bigrams, trigrams)\n",
    "\n",
    "    # Combine unigrams, filtered bigrams, and filtered trigrams\n",
    "    #all_tokens = unigrams + bigrams + trigrams\n",
    "\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi Visualisasi\n",
    "def visualize_graph(G, labels):\n",
    "    # Remove self-loops (edges that connect a node to itself)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    #nx.draw(G, pos=pos, with_labels=False, font_weight=\"bold\", node_size=5000, node_color='skyblue')\n",
    "    nx.draw(G, pos=pos, with_labels=False, font_weight=\"bold\")\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2vec Model\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def load_word2vec_model(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"The provided Word2Vec model path does not exist: {model_path}\")\n",
    "    \n",
    "    w2v_model = Word2Vec.load(model_path) \n",
    "    available_tokens = set(w2v_model.wv.key_to_index)\n",
    "    \n",
    "    return w2v_model, available_tokens\n",
    "\n",
    "def get_unique_tokens_pos(all_tokens, pos_model_path):\n",
    "    \"\"\"\n",
    "    Get unique POS tags for tokens.\n",
    "    \"\"\"\n",
    "    pos_model_path = os.path.join(repo_root, \"notebooks/nlp-id_retraining/train_tuned.pkl\")\n",
    "    postagger = PosTag(pos_model_path)\n",
    "    pos_tokens = []\n",
    "    seen_tokens = set()\n",
    "    \n",
    "    for token in all_tokens:\n",
    "        if token not in seen_tokens:\n",
    "            seen_tokens.add(token)\n",
    "            tokens_pos = postagger.get_phrase_tag(token)\n",
    "            pos_tokens.append(tokens_pos)\n",
    "    return pos_tokens\n",
    "\n",
    "def flatten_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Flatten a list of lists into a single list.\n",
    "    \"\"\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def get_phrase_embedding(phrase, w2v_model):\n",
    "    \"\"\"Get the averaged word embedding for a phrase.\"\"\"\n",
    "    words = phrase.split()\n",
    "    embeddings = [w2v_model.wv[word] for word in words if word in w2v_model.wv.key_to_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target 1 : Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine_similarity(w1, w2, w2v_model):\n",
    "    if w1 not in w2v_model.wv or w2 not in w2v_model.wv:\n",
    "        return 0\n",
    "    vec1 = w2v_model.wv[w1]\n",
    "    vec2 = w2v_model.wv[w2]\n",
    "    similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXTRANK and ADJUSTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec Model\n",
    "def load_word2vec_model(model_path):\n",
    "    w2v_model = Word2Vec.load(model_path)\n",
    "    available_tokens = w2v_model.wv.index_to_key\n",
    "    return w2v_model, available_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postagging Function\n",
    "def postag_tokens(tokens, postagger):\n",
    "    pos_tokens = [postagger.get_phrase_tag(token) for token in tokens]\n",
    "    # Flatten the list\n",
    "    return [item for sublist in pos_tokens for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Co-occurrence Matrix\n",
    "def build_co_occurrence_matrix(words, window_size=3):\n",
    "    co_occurrence = defaultdict(int)\n",
    "    for i in range(len(words) - window_size + 1):\n",
    "        window = words[i:i+window_size]\n",
    "        for j in range(window_size):\n",
    "            for k in range(j+1, window_size):\n",
    "                w1, w2 = sorted([window[j], window[k]])\n",
    "                if w1 != w2:\n",
    "                    co_occurrence[(w1, w2)] += 1\n",
    "    return co_occurrence\n",
    "\n",
    "# Build Graph and Compute TextRank\n",
    "def build_graph_and_compute_textrank(co_occurrence, w2v_model):\n",
    "    G = nx.Graph()\n",
    "    for (w1, w2), weight1 in co_occurrence.items():\n",
    "        weight2 = get_cosine_similarity(w1, w2, w2v_model)\n",
    "        weight3 = weight1 * weight2\n",
    "        if weight2 > 0:\n",
    "            G.add_edge(w1, w2, weight=weight3)\n",
    "    return nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and Rank Keywords\n",
    "def filter_and_rank_keywords(scores, stopwords, num_keywords=10):\n",
    "    ranked_words = sorted(((score, word) for word, score in scores.items()), reverse=True)\n",
    "    ranked_words_nstopword = [(score, word) for score, word in ranked_words if word not in stopwords]\n",
    "    \n",
    "    keyphrases_with_scores = []\n",
    "    seen_tokens = set()\n",
    "    for score, token in ranked_words_nstopword:\n",
    "        if token not in seen_tokens:\n",
    "            keyphrases_with_scores.append((token, score))\n",
    "            seen_tokens.add(token)\n",
    "            if len(keyphrases_with_scores) >= num_keywords:\n",
    "                break\n",
    "\n",
    "    return keyphrases_with_scores\n",
    "\n",
    "# Attach POS Tags to Keywords\n",
    "def attach_pos_tags(keywords, pos_tokens):\n",
    "    pos_dict = dict(pos_tokens)\n",
    "    return [(word, score, pos_dict.get(word, 'UNK')) for word, score in keywords]\n",
    "\n",
    "# Filter by Selected POS Tags\n",
    "def filter_by_pos(keywords_with_pos, selected_pos):\n",
    "    return [item for item in keywords_with_pos if item[2] in selected_pos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SAMPLE SINGLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template document jtb gpf project mengacu kepada dokumen jtb cp ctr exhibit coordination procedure kami sampaikan template document yang akan dipergunakan pada proyek jambaran tiung biru jtb gas processing facilities gpf demikian disampaikan sebagai acuan pengelolaan dokumen atas perhatiannya kami ucapkan terima kasih\n",
      "================================================================\n",
      "['template document', 'jtb', 'gpf', 'project', 'mengacu', 'kepada', 'dokumen', 'jtb', 'cp', 'ctr', 'exhibit', 'coordination', 'procedure', 'kami', 'sampaikan', 'template document', 'yang', 'akan', 'dipergunakan', 'pada', 'proyek', 'jambaran', 'tiung', 'biru', 'jtb', 'gas', 'processing', 'facilities', 'gpf', 'demikian', 'disampaikan', 'sebagai', 'acuan', 'pengelolaan', 'dokumen', 'atas', 'perhatiannya', 'kami', 'ucapkan', 'terima', 'kasih']\n",
      "[('template document', 'NP'), ('jtb', 'SC'), ('gpf', 'NN'), ('project', 'NN'), ('mengacu', 'VP'), ('kepada', 'IN'), ('dokumen', 'NN'), ('jtb', 'SC'), ('cp', 'NN'), ('ctr', 'NN'), ('exhibit', 'NN'), ('coordination', 'FW'), ('procedure', 'NN'), ('kami', 'PR'), ('sampaikan', 'VP'), ('template document', 'NP'), ('yang', 'PR'), ('akan', 'ADV'), ('dipergunakan', 'VP'), ('pada', 'IN'), ('proyek', 'NN'), ('jambaran', 'NN'), ('tiung', 'NN'), ('biru', 'ADJP'), ('jtb', 'SC'), ('gas', 'NN'), ('processing', 'NN'), ('facilities', 'NN'), ('gpf', 'NN'), ('demikian', 'PR'), ('disampaikan', 'VP'), ('sebagai', 'IN'), ('acuan', 'NN'), ('pengelolaan', 'NN'), ('dokumen', 'NN'), ('atas', 'IN'), ('perhatian', 'NN'), ('nya', 'PR'), ('kami', 'PR'), ('ucapkan', 'VP'), ('terima', 'VP'), ('kasih', 'NN')]\n",
      "mengandung stopword: {'gpf': 0.031004580057689666, 'jtb': 0.042714072587200905, 'project': 0.0079537577738825, 'kepada': 0.01831738458298862, 'mengacu': 0.0098061821279634, 'dokumen': 0.0496617100431149, 'cp': 0.026162215495111246, 'ctr': 0.03761248591823455, 'exhibit': 0.03598238904279516, 'coordination': 0.037039129642124746, 'procedure': 0.025011839066630258, 'kami': 0.046781338105006245, 'sampaikan': 0.01611991981667493, 'yang': 0.03128460718051381, 'akan': 0.03986792227265744, 'dipergunakan': 0.014238969441662, 'pada': 0.034087636251117354, 'proyek': 0.020320538912728357, 'jambaran': 0.03124877814401084, 'tiung': 0.03719014230212127, 'biru': 0.023885916597959477, 'gas': 0.02003647589229394, 'processing': 0.03793689153803367, 'facilities': 0.03505895602258495, 'demikian': 0.018184970049531173, 'disampaikan': 0.024632485797690715, 'sebagai': 0.03175781933855937, 'acuan': 0.04120222062483282, 'pengelolaan': 0.031551433652304665, 'atas': 0.030460860543675587, 'perhatiannya': 0.02660840872553917, 'ucapkan': 0.04269011001314918, 'terima': 0.028725931361848037, 'kasih': 0.014861921077768833}\n",
      "================================================================\n",
      "stopword di filter : [('acuan', 0.04120222062483282), ('processing', 0.03793689153803367), ('ctr', 0.03761248591823455), ('tiung', 0.03719014230212127), ('coordination', 0.037039129642124746), ('exhibit', 0.03598238904279516), ('facilities', 0.03505895602258495), ('pengelolaan', 0.031551433652304665), ('jambaran', 0.03124877814401084), ('perhatiannya', 0.02660840872553917)]\n",
      "================================================================\n",
      "diberi postag : [('acuan', 0.04120222062483282, 'NN'), ('processing', 0.03793689153803367, 'NN'), ('ctr', 0.03761248591823455, 'NN'), ('tiung', 0.03719014230212127, 'NN'), ('coordination', 0.037039129642124746, 'FW'), ('exhibit', 0.03598238904279516, 'NN'), ('facilities', 0.03505895602258495, 'NN'), ('pengelolaan', 0.031551433652304665, 'NN'), ('jambaran', 0.03124877814401084, 'NN'), ('perhatiannya', 0.02660840872553917, 'UNK')]\n",
      "================================================================\n",
      "filtered postag : [('acuan', 0.04120222062483282, 'NN'), ('processing', 0.03793689153803367, 'NN'), ('ctr', 0.03761248591823455, 'NN'), ('tiung', 0.03719014230212127, 'NN'), ('exhibit', 0.03598238904279516, 'NN'), ('facilities', 0.03505895602258495, 'NN'), ('pengelolaan', 0.031551433652304665, 'NN'), ('jambaran', 0.03124877814401084, 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Load Word2Vec Model\n",
    "w2v_model_path = os.path.join(repo_root, \"notebooks/word2vec_model/w2v_wiki_own_phrase_training_200.model\")\n",
    "w2v_model, available_tokens = load_word2vec_model(w2v_model_path)\n",
    "#sample_tokens = list(available_tokens)[:5]\n",
    "#print(sample_tokens)\n",
    "\n",
    "# Processing Text\n",
    "text = df[\"text\"][1]\n",
    "words = detect_all_tokens(text)\n",
    "print(text)\n",
    "print(\"================================================================\")\n",
    "print(words)\n",
    "\n",
    "# Postagging\n",
    "from nlp_id.postag import PosTag\n",
    "postagger = PosTag() \n",
    "pos_tokens = postag_tokens(words, postagger)\n",
    "print(pos_tokens)\n",
    "\n",
    "# Building Co-occurrence Matrix\n",
    "co_occurrence = build_co_occurrence_matrix(words)\n",
    "\n",
    "# Building Graph and Computing TextRank\n",
    "scores = build_graph_and_compute_textrank(co_occurrence, w2v_model)\n",
    "print(\"mengandung stopword:\", scores)\n",
    "print(\"================================================================\")\n",
    "\n",
    "# Filtering and Ranking Keywords\n",
    "keyphrases_with_scores = filter_and_rank_keywords(scores, stopwords)\n",
    "print(\"stopword di filter :\",keyphrases_with_scores)\n",
    "print(\"================================================================\")\n",
    "\n",
    "# Attaching POS Tags\n",
    "keywords_with_pos = attach_pos_tags(keyphrases_with_scores, pos_tokens)\n",
    "print(\"diberi postag :\",keywords_with_pos)\n",
    "print(\"================================================================\")\n",
    "\n",
    "# Filtering by Selected POS Tags\n",
    "selected_pos_tags = {'NN', 'NNP', 'VB', 'NP', 'VP'}\n",
    "filtered_list = filter_by_pos(keywords_with_pos, selected_pos_tags)\n",
    "print(\"filtered postag :\", filtered_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index 2...! Done\n",
      "Processing index 3...! Done\n",
      "Processing index 4...! Done\n",
      "Processing index 5...! Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_1</th>\n",
       "      <th>pos_2</th>\n",
       "      <th>pos_3</th>\n",
       "      <th>pos_4</th>\n",
       "      <th>pos_5</th>\n",
       "      <th>pos_6</th>\n",
       "      <th>pos_7</th>\n",
       "      <th>pos_8</th>\n",
       "      <th>pos_9</th>\n",
       "      <th>pos_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>usulan</td>\n",
       "      <td>artikel</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>diskusi</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>tabel</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengadaan</td>\n",
       "      <td>konstruksi</td>\n",
       "      <td>deliverables</td>\n",
       "      <td>fungsi</td>\n",
       "      <td>menanggapi</td>\n",
       "      <td>inspeksi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>VP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iwan</td>\n",
       "      <td>permit</td>\n",
       "      <td>request</td>\n",
       "      <td>hamzah</td>\n",
       "      <td>manager</td>\n",
       "      <td>bp</td>\n",
       "      <td>kunjungan</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_1       key_2         key_3    key_4       key_5          key_6  \\\n",
       "0     kantor     ruangan        usulan  artikel      lokasi  accommodation   \n",
       "1  pengadaan  konstruksi  deliverables   fungsi  menanggapi       inspeksi   \n",
       "2       iwan      permit       request   hamzah     manager             bp   \n",
       "\n",
       "       key_7        key_8  key_9  key_10  ...  pos_1  pos_2  pos_3  pos_4  \\\n",
       "0    diskusi  klarifikasi  tabel       0  ...     NN     NN     NN     NN   \n",
       "1          0            0      0       0  ...     NN     NN     NN     NN   \n",
       "2  kunjungan     lapangan      0       0  ...     NN     NN     NN     NN   \n",
       "\n",
       "   pos_5  pos_6  pos_7  pos_8  pos_9  pos_10  \n",
       "0     NN     NN     NN     NN     NN       0  \n",
       "1     VP     NN      0      0      0       0  \n",
       "2     NN     NN     NN     NN      0       0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postagger = PosTag()\n",
    "# Load Word2Vec Model\n",
    "w2v_model_path = os.path.join(repo_root, \"notebooks/word2vec_model/w2v_wiki_own_phrase_training_200.model\")\n",
    "w2v_model, available_tokens = load_word2vec_model(w2v_model_path)\n",
    "\n",
    "predict_textrank = pd.DataFrame()\n",
    "#for i in df.index:\n",
    "for i in df.loc[2:5].index:    \n",
    "    print('Processing index', i, end='...! ')\n",
    "    # Processing Text\n",
    "    text = df[\"text\"][i]\n",
    "    words = detect_all_tokens(text)\n",
    "    # Postagging\n",
    "    pos_tokens = postag_tokens(words, postagger)\n",
    "    # Building Co-occurrence Matrix\n",
    "    co_occurrence = build_co_occurrence_matrix(words)\n",
    "    # Building Graph and Computing TextRank\n",
    "    scores = build_graph_and_compute_textrank(co_occurrence, w2v_model)\n",
    "    # Filtering and Ranking Keywords\n",
    "    keyphrases_with_scores = filter_and_rank_keywords(scores, stopwords)\n",
    "    # Attaching POS Tags\n",
    "    keywords_with_pos = attach_pos_tags(keyphrases_with_scores, pos_tokens)\n",
    "    # Filtering by Selected POS Tags\n",
    "    selected_pos_tags = {'NN', 'NNP', 'VB', 'NP', 'VP'}\n",
    "    filtered_list = filter_by_pos(keywords_with_pos, selected_pos_tags)\n",
    "\n",
    "    df_keyphrases = pd.DataFrame(filtered_list, columns=['Keyword', 'Score', 'pos'])\n",
    "    a = pd.DataFrame(df_keyphrases.Keyword).T.reset_index(drop=True)\n",
    "    a = a.reindex(columns=range(10), fill_value=0)\n",
    "    b = pd.DataFrame(df_keyphrases.Score).round(3).T.reset_index(drop=True)\n",
    "    b = b.reindex(columns=range(10), fill_value=0)\n",
    "    c = pd.DataFrame(df_keyphrases.pos).round(3).T.reset_index(drop=True)\n",
    "    c = c.reindex(columns=range(10), fill_value=0)\n",
    "    df_keyphrases = pd.concat([a, b, c], axis=1)\n",
    "\n",
    "    # Check if there are missing columns and add them with zero values\n",
    "    missing_columns = 30 - df_keyphrases.shape[1]\n",
    "    for _ in range(missing_columns):\n",
    "        df_keyphrases[df_keyphrases.shape[1]] = 0\n",
    "\n",
    "    df_keyphrases.columns = ['key_1', 'key_2','key_3', 'key_4', 'key_5','key_6', 'key_7', 'key_8','key_9','key_10',\n",
    "                             'score_1', 'score_2','score_3','score_4', 'score_5','score_6','score_7', 'score_8','score_9','score_10',\n",
    "                             'pos_1', 'pos_2','pos_3', 'pos_4', 'pos_5','pos_6', 'pos_7', 'pos_8','pos_9','pos_10'] \n",
    "    predict_textrank = pd.concat([predict_textrank, df_keyphrases], ignore_index=True)\n",
    "    print('Done')\n",
    "predict_textrank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval\n",
    "\n",
    "targets = df[[\"k1\", \"k2\", \"k3\",\"k4\", \"k5\", \"k6\",\"k7\"]].values.tolist()\n",
    "df_targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1     key_2       key_3     key_4     key_5     key_6     key_7  \\\n",
       "0  no_match  no_match  full_match  no_match  no_match  no_match  no_match   \n",
       "1  no_match  no_match    no_match  no_match  no_match  no_match  no_match   \n",
       "2  no_match  no_match    no_match  no_match  no_match  no_match  no_match   \n",
       "\n",
       "      key_8     key_9    key_10  flex_recall  flex_prec  \n",
       "0  no_match  no_match  no_match        0.143        0.1  \n",
       "1  no_match  no_match  no_match        0.000        0.0  \n",
       "2  no_match  no_match  no_match        0.000        0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 10\n",
    "predict_textrank_list_10 = predict_textrank[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10']].values.tolist()\n",
    "eval_textrank_10 = eval(predict_textrank_list_10, targets, True).round(3)\n",
    "eval_textrank_10.columns = ['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_10 = eval_textrank_10[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.036\n",
       "precision     0.025\n",
       "F1            0.029"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_10 = eval_textrank_10['flex_recall'].mean()\n",
    "textrank_prec_10 = eval_textrank_10['flex_prec'].mean()\n",
    "textrank_f1_10 = 2 * (textrank_prec_10 * textrank_recall_10) / (textrank_prec_10 + textrank_recall_10)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_10 = pd.DataFrame({'textrank': [textrank_recall_10, textrank_prec_10, textrank_f1_10]}, index=['recall', 'precision', 'F1'])\n",
    "summary_10 = summary_10.round(3)\n",
    "summary_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1     key_2       key_3     key_4     key_5  flex_recall  flex_prec\n",
       "0  no_match  no_match  full_match  no_match  no_match        0.143        0.2\n",
       "1  no_match  no_match    no_match  no_match  no_match        0.000        0.0\n",
       "2  no_match  no_match    no_match  no_match  no_match        0.000        0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 5\n",
    "predict_textrank_list_5 = predict_textrank[['key_1','key_2','key_3', 'key_4','key_5']].values.tolist()\n",
    "eval_textrank_5 = eval(predict_textrank_list_5, targets, True).round(3)\n",
    "eval_textrank_5.columns = ['key_1','key_2','key_3', 'key_4','key_5','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_5 = eval_textrank_5[['key_1','key_2','key_3', 'key_4','key_5', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.036\n",
       "precision     0.050\n",
       "F1            0.042"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_5 = eval_textrank_5['flex_recall'].mean()\n",
    "textrank_prec_5 = eval_textrank_5['flex_prec'].mean()\n",
    "textrank_f1_5 = 2 * (textrank_prec_5 * textrank_recall_5) / (textrank_prec_5 + textrank_recall_5)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_5 = pd.DataFrame({'textrank': [textrank_recall_5, textrank_prec_5, textrank_f1_5]}, index=['recall', 'precision', 'F1'])\n",
    "summary_5 = summary_5.round(3)\n",
    "summary_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1     key_2       key_3  flex_recall  flex_prec\n",
       "0  no_match  no_match  full_match        0.143      0.333\n",
       "1  no_match  no_match    no_match        0.000      0.000\n",
       "2  no_match  no_match    no_match        0.000      0.000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 3\n",
    "predict_textrank_list_3 = predict_textrank[['key_1','key_2','key_3']].values.tolist()\n",
    "eval_textrank_3 = eval(predict_textrank_list_3, targets, True).round(3)\n",
    "eval_textrank_3.columns = ['key_1', 'key_2','key_3','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_3 = eval_textrank_3[['key_1', 'key_2','key_3', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.036\n",
       "precision     0.083\n",
       "F1            0.050"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_3 = eval_textrank_3['flex_recall'].mean()\n",
    "textrank_prec_3 = eval_textrank_3['flex_prec'].mean()\n",
    "textrank_f1_3 = 2 * (textrank_prec_3 * textrank_recall_3) / (textrank_prec_3 + textrank_recall_3)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_3 = pd.DataFrame({'textrank': [textrank_recall_3, textrank_prec_3, textrank_f1_3]}, index=['recall', 'precision', 'F1'])\n",
    "summary_3 = summary_3.round(3)\n",
    "summary_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>usulan</td>\n",
       "      <td>artikel</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>diskusi</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>tabel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengadaan</td>\n",
       "      <td>konstruksi</td>\n",
       "      <td>deliverables</td>\n",
       "      <td>fungsi</td>\n",
       "      <td>menanggapi</td>\n",
       "      <td>inspeksi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iwan</td>\n",
       "      <td>permit</td>\n",
       "      <td>request</td>\n",
       "      <td>hamzah</td>\n",
       "      <td>manager</td>\n",
       "      <td>bp</td>\n",
       "      <td>kunjungan</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_1       key_2         key_3    key_4       key_5          key_6  \\\n",
       "0     kantor     ruangan        usulan  artikel      lokasi  accommodation   \n",
       "1  pengadaan  konstruksi  deliverables   fungsi  menanggapi       inspeksi   \n",
       "2       iwan      permit       request   hamzah     manager             bp   \n",
       "\n",
       "       key_7        key_8  key_9  key_10  ...       key_3     key_4     key_5  \\\n",
       "0    diskusi  klarifikasi  tabel     0.0  ...  full_match  no_match  no_match   \n",
       "1          0            0      0     0.0  ...    no_match  no_match  no_match   \n",
       "2  kunjungan     lapangan      0     0.0  ...    no_match  no_match  no_match   \n",
       "\n",
       "      key_6     key_7     key_8     key_9    key_10  flex_recall  flex_prec  \n",
       "0  no_match  no_match  no_match  no_match  no_match        0.143        0.1  \n",
       "1  no_match  no_match  no_match  no_match  no_match        0.000        0.0  \n",
       "2  no_match  no_match  no_match  no_match  no_match        0.000        0.0  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_10 = pd.concat([predict_textrank, df_targets, eval_textrank_10], axis=1)\n",
    "predict_textrank_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>usulan</td>\n",
       "      <td>artikel</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>diskusi</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>tabel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengadaan</td>\n",
       "      <td>konstruksi</td>\n",
       "      <td>deliverables</td>\n",
       "      <td>fungsi</td>\n",
       "      <td>menanggapi</td>\n",
       "      <td>inspeksi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iwan</td>\n",
       "      <td>permit</td>\n",
       "      <td>request</td>\n",
       "      <td>hamzah</td>\n",
       "      <td>manager</td>\n",
       "      <td>bp</td>\n",
       "      <td>kunjungan</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_1       key_2         key_3    key_4       key_5          key_6  \\\n",
       "0     kantor     ruangan        usulan  artikel      lokasi  accommodation   \n",
       "1  pengadaan  konstruksi  deliverables   fungsi  menanggapi       inspeksi   \n",
       "2       iwan      permit       request   hamzah     manager             bp   \n",
       "\n",
       "       key_7        key_8  key_9  key_10  ...                     4  \\\n",
       "0    diskusi  klarifikasi  tabel     0.0  ...                   NaN   \n",
       "1          0            0      0     0.0  ...               dokumen   \n",
       "2  kunjungan     lapangan      0     0.0  ...  services for company   \n",
       "\n",
       "           5    6     key_1     key_2       key_3     key_4     key_5  \\\n",
       "0        NaN  NaN  no_match  no_match  full_match  no_match  no_match   \n",
       "1        NaN  NaN  no_match  no_match    no_match  no_match  no_match   \n",
       "2  exhibit a  NaN  no_match  no_match    no_match  no_match  no_match   \n",
       "\n",
       "   flex_recall  flex_prec  \n",
       "0        0.143        0.2  \n",
       "1        0.000        0.0  \n",
       "2        0.000        0.0  \n",
       "\n",
       "[3 rows x 44 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_5 = pd.concat([predict_textrank, df_targets, eval_textrank_5], axis=1)\n",
    "predict_textrank_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>usulan</td>\n",
       "      <td>artikel</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>accommodation</td>\n",
       "      <td>diskusi</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>tabel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>usulan</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pengadaan</td>\n",
       "      <td>konstruksi</td>\n",
       "      <td>deliverables</td>\n",
       "      <td>fungsi</td>\n",
       "      <td>menanggapi</td>\n",
       "      <td>inspeksi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>acuan</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iwan</td>\n",
       "      <td>permit</td>\n",
       "      <td>request</td>\n",
       "      <td>hamzah</td>\n",
       "      <td>manager</td>\n",
       "      <td>bp</td>\n",
       "      <td>kunjungan</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>lingkup kerja</td>\n",
       "      <td>akomodasi</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_1       key_2         key_3    key_4       key_5          key_6  \\\n",
       "0     kantor     ruangan        usulan  artikel      lokasi  accommodation   \n",
       "1  pengadaan  konstruksi  deliverables   fungsi  menanggapi       inspeksi   \n",
       "2       iwan      permit       request   hamzah     manager             bp   \n",
       "\n",
       "       key_7        key_8  key_9  key_10  ...              2            3  \\\n",
       "0    diskusi  klarifikasi  tabel     0.0  ...         usulan    pengganti   \n",
       "1          0            0      0     0.0  ...          acuan  pengelolaan   \n",
       "2  kunjungan     lapangan      0     0.0  ...  lingkup kerja    akomodasi   \n",
       "\n",
       "                      4          5    6     key_1     key_2       key_3  \\\n",
       "0                   NaN        NaN  NaN  no_match  no_match  full_match   \n",
       "1               dokumen        NaN  NaN  no_match  no_match    no_match   \n",
       "2  services for company  exhibit a  NaN  no_match  no_match    no_match   \n",
       "\n",
       "   flex_recall  flex_prec  \n",
       "0        0.143      0.333  \n",
       "1        0.000      0.000  \n",
       "2        0.000      0.000  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_3 = pd.concat([predict_textrank, df_targets, eval_textrank_3], axis=1)\n",
    "predict_textrank_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def write_excel(df, sheet_name, filename):\n",
    "    \"\"\"\n",
    "    Writes the given dataframe to an excel file with the given filename and sheet name.\n",
    "    If the sheet already exists in the file, the data in the sheet will be overwritten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "            if sheet_name in writer.book.sheetnames:\n",
    "                # If sheet already exists, remove it\n",
    "                sheet = writer.book[sheet_name]\n",
    "                writer.book.remove(sheet)\n",
    "\n",
    "            # Write the dataframe to the excel file\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to excel file\n",
    "#from utils import write_excel\n",
    "\n",
    "sheet_name_10 = 'SE5_tr_w2v_posfilter_10'\n",
    "sheet_name_5 = 'SE5_tr_w2v_posfilter_5'\n",
    "sheet_name_3 = 'SE5_tr_w2v_posfilter_3'\n",
    "\n",
    "output_file = 'SE5_tr_w2v_posfilter.xlsx'\n",
    "write_excel(predict_textrank_10, sheet_name_10, output_file)\n",
    "write_excel(predict_textrank_5, sheet_name_5, output_file)\n",
    "write_excel(predict_textrank_3, sheet_name_3, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
