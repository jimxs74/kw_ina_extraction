{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r30_lg.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "'''\n",
    "stopwords tidak masuk dalam preprocessing\n",
    "'''\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df['text'].apply(preprocess)\n",
    "df[\"judul\"] = df[\"judul\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = os.path.join(repo_root, \"notebooks/stopwords_tuning/all_stop_words.txt\")\n",
    "with open(stopwords_path, 'r') as file:\n",
    "    stopwords = set(file.read().strip().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nlp_id_local.tokenizer import PhraseTokenizer \n",
    "from nlp_id_local.postag import PosTag\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def generate_ngrams(words, n=2):\n",
    "    \"\"\"Generate ngrams from a list of words.\"\"\"\n",
    "    return [\" \".join(gram) for gram in ngrams(words, n)]\n",
    "\n",
    "def detect_bigram(text):\n",
    "    \n",
    "    tokenizer = PhraseTokenizer()\n",
    "    phrases = tokenizer.tokenize(text)\n",
    "    # Include only bigrams whose individual words are in available_tokens\n",
    "    bigrams_only = [phrase for phrase in phrases if phrase.count(\" \") == 1]\n",
    "\n",
    "    return bigrams_only\n",
    "\n",
    "def detect_trigram(text):\n",
    "\n",
    "    tokenizer = PhraseTokenizer()\n",
    "    phrases = tokenizer.tokenize(text)\n",
    "    # Include only trigrams whose individual words are in available_tokens\n",
    "    trigrams_only = [phrase for phrase in phrases if phrase.count(\" \") == 2 ]\n",
    "\n",
    "    return trigrams_only\n",
    "\n",
    "def detect_all_tokens(text):\n",
    "    unigrams = [word for word in text.split()]\n",
    "    bigrams = detect_bigram(text)\n",
    "    trigrams = detect_trigram(text)\n",
    "    \n",
    "    # Combine unigrams, filtered bigrams, and filtered trigrams\n",
    "    all_tokens = unigrams + bigrams + trigrams\n",
    "\n",
    "    return all_tokens\n",
    "\n",
    "def visualize_graph(G, labels):\n",
    "    # Remove self-loops (edges that connect a node to itself)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    #nx.draw(G, pos=pos, with_labels=False, font_weight=\"bold\", node_size=5000, node_color='skyblue')\n",
    "    nx.draw(G, pos=pos, with_labels=False, font_weight=\"bold\")\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def load_word2vec_model(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"The provided Word2Vec model path does not exist: {model_path}\")\n",
    "    \n",
    "    w2v_model = Word2Vec.load(model_path) \n",
    "    available_tokens = set(w2v_model.wv.key_to_index)\n",
    "    \n",
    "    return w2v_model, available_tokens\n",
    "\n",
    "# Example usage\n",
    "model_path = os.path.join(repo_root, \"models/w2v_200/idwiki_word2vec_200_new_lower.model\")\n",
    "w2v_model, available_tokens = load_word2vec_model(model_path)\n",
    "\n",
    "# Show a sample of available tokens\n",
    "sample_tokens = list(available_tokens)[:5]\n",
    "sample_tokens\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine_similarity(w1, w2, w2v_model):\n",
    "    if w1 not in w2v_model.wv or w2 not in w2v_model.wv:\n",
    "        return 0\n",
    "    vec1 = w2v_model.wv[w1]\n",
    "    vec2 = w2v_model.wv[w2]\n",
    "    similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORATORY PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mcallister', 'suffers', 'vandalisme', 'ahriman', 'mgf']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "model_path = os.path.join(repo_root, \"models/w2v_200/idwiki_word2vec_200_new_lower.model\")\n",
    "w2v_model, available_tokens = load_word2vec_model(model_path)\n",
    "\n",
    "# Show a sample of available tokens\n",
    "sample_tokens = list(available_tokens)[:5]\n",
    "sample_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(repo_root, \"notebooks/nlp-id_retraining/train_tuned.pkl\")\n",
    "\n",
    "def get_unique_tokens_pos(all_tokens, model_path):\n",
    "    \"\"\"\n",
    "    Get unique POS tags for tokens.\n",
    "    \"\"\"\n",
    "    postagger = PosTag(model_path)\n",
    "    pos_tokens = []\n",
    "    seen_tokens = set()\n",
    "    \n",
    "    for token in all_tokens:\n",
    "        if token not in seen_tokens:\n",
    "            seen_tokens.add(token)\n",
    "            tokens_pos = postagger.get_phrase_tag(token)\n",
    "            pos_tokens.append(tokens_pos)\n",
    "    return pos_tokens\n",
    "\n",
    "def flatten_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Flatten a list of lists into a single list.\n",
    "    \"\"\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def filter_tokens_by_pos(flat_tokens, pos_filters):\n",
    "    \"\"\"\n",
    "    Filter tokens based on their POS tags and ensure they're unique.\n",
    "    \"\"\"\n",
    "    seen_tokens = set()\n",
    "    return [token[0] for token in flat_tokens if token[1] in pos_filters and not (token[0] in seen_tokens or seen_tokens.add(token[0]))]\n",
    "\n",
    "def get_phrase_embedding(phrase, w2v_model):\n",
    "    \"\"\"Get the averaged word embedding for a phrase.\"\"\"\n",
    "    words = phrase.split()\n",
    "    embeddings = [w2v_model.wv[word] for word in words if word in w2v_model.wv.key_to_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_ngram_type(token):\n",
    "    return len(token.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank(text, judul, num_keywords=10):\n",
    "    # Tokenize the text\n",
    "    words = detect_all_tokens(text)\n",
    "    # Load stopwords for the specified language\n",
    "    stop_words = stopwords\n",
    "    \n",
    "    # Filter out stopwords and punctuation\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Path to the POS tagging model\n",
    "    model_path = os.path.join(repo_root, \"notebooks/nlp-id_retraining/train_tuned.pkl\")\n",
    "    \n",
    "    # Get unique POS tags for tokens\n",
    "    pos_tokens = get_unique_tokens_pos(words, model_path)\n",
    "    flat_pos_tokens = flatten_list_of_lists(pos_tokens)\n",
    "    selected_pos = {'NN', 'NNP', 'VB', 'NP', 'VP'}  # Exclude FW\n",
    "    filtered_tokens = filter_tokens_by_pos(flat_pos_tokens, selected_pos)\n",
    "    \n",
    "    # Use filtered_tokens instead of words for the following processing\n",
    "    # Build a co-occurrence matrix\n",
    "    co_occurrence = defaultdict(int)\n",
    "    window_size = 3\n",
    "    for i in range(len(filtered_tokens) - window_size + 1):\n",
    "        window = filtered_tokens[i:i+window_size]\n",
    "        for j in range(window_size):\n",
    "            for k in range(j+1, window_size):\n",
    "                w1, w2 = sorted([window[j], window[k]])\n",
    "                if w1 != w2:\n",
    "                    co_occurrence[(w1, w2)] += 1\n",
    "    \n",
    "    # Build a graph\n",
    "    G = nx.Graph()\n",
    "    for (w1, w2), weight1 in co_occurrence.items():\n",
    "        weight2 = get_cosine_similarity(w1, w2, w2v_model)\n",
    "        weight3 = weight1 * weight2\n",
    "        if weight2 > 0:\n",
    "            G.add_edge(w1, w2, weight=weight3)\n",
    "    \n",
    "    # Compute TextRank scores\n",
    "    scores = nx.pagerank(G)\n",
    "\n",
    "    # Modify scores based on n-gram type\n",
    "    for token in scores:\n",
    "        ngram_type = get_ngram_type(token)\n",
    "        if ngram_type == 1:  # Unigram\n",
    "            pass  # No change to score\n",
    "        elif ngram_type == 2:  # Bigram\n",
    "            scores[token] *= 2  # Double the score\n",
    "        elif ngram_type == 3:  # Trigram\n",
    "            scores[token] *= 2  # Double the score\n",
    "\n",
    "    # Modify scores if token is in title letter\n",
    "    for token in scores:\n",
    "        if any(token in title for title in judul):\n",
    "            scores[token] *= 2\n",
    "    \n",
    "    # Prepare labels\n",
    "    labels = {node: f'{node}\\n({score:.2f})' for node, score in scores.items()}\n",
    "\n",
    "    # Sort words by scores\n",
    "    ranked_words = sorted(((score, word) for word, score in scores.items()), reverse=True)\n",
    "    \n",
    "    # Extract the top keywords\n",
    "    keywords = [word for score, word in ranked_words[:num_keywords]]\n",
    "\n",
    "    keyphrases_with_scores = []\n",
    "    seen_tokens = set()  # Set to keep track of tokens that have already been added\n",
    "\n",
    "    for score, token in ranked_words:\n",
    "        if token not in seen_tokens:\n",
    "            keyphrases_with_scores.append((token, score))\n",
    "            seen_tokens.add(token)  # Mark the token as seen\n",
    "            if len(keyphrases_with_scores) >= num_keywords:\n",
    "                break\n",
    "    \n",
    "    return keyphrases_with_scores, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITERASI UNTUK ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index 0...! Done\n",
      "Processing index 1...! Done\n",
      "Processing index 2...! Done\n",
      "Processing index 3...! Done\n",
      "Processing index 4...! Done\n",
      "Processing index 5...! Done\n",
      "Processing index 6...! Done\n",
      "Processing index 7...! Done\n",
      "Processing index 8...! Done\n",
      "Processing index 9...! Done\n",
      "Processing index 10...! Done\n",
      "Processing index 11...! Done\n",
      "Processing index 12...! Done\n",
      "Processing index 13...! Done\n",
      "Processing index 14...! Done\n",
      "Processing index 15...! Done\n",
      "Processing index 16...! Done\n",
      "Processing index 17...! Done\n",
      "Processing index 18...! Done\n",
      "Processing index 19...! Done\n",
      "Processing index 20...! Done\n",
      "Processing index 21...! Done\n",
      "Processing index 22...! Done\n",
      "Processing index 23...! Done\n",
      "Processing index 24...! Done\n",
      "Processing index 25...! Done\n",
      "Processing index 26...! Done\n",
      "Processing index 27...! Done\n",
      "Processing index 28...! Done\n",
      "Processing index 29...! Done\n",
      "Processing index 30...! Done\n",
      "Processing index 31...! Done\n",
      "Processing index 32...! Done\n",
      "Processing index 33...! Done\n",
      "Processing index 34...! Done\n",
      "Processing index 35...! Done\n",
      "Processing index 36...! Done\n",
      "Processing index 37...! Done\n",
      "Processing index 38...! Done\n",
      "Processing index 39...! Done\n",
      "Processing index 40...! Done\n",
      "Processing index 41...! Done\n",
      "Processing index 42...! Done\n",
      "Processing index 43...! Done\n",
      "Processing index 44...! Done\n",
      "Processing index 45...! Done\n",
      "Processing index 46...! Done\n",
      "Processing index 47...! Done\n",
      "Processing index 48...! Done\n",
      "Processing index 49...! Done\n",
      "Processing index 50...! Done\n",
      "Processing index 51...! Done\n",
      "Processing index 52...! Done\n",
      "Processing index 53...! Done\n",
      "Processing index 54...! Done\n",
      "Processing index 55...! Done\n",
      "Processing index 56...! Done\n",
      "Processing index 57...! Done\n",
      "Processing index 58...! Done\n",
      "Processing index 59...! Done\n",
      "Processing index 60...! Done\n",
      "Processing index 61...! Done\n",
      "Processing index 62...! Done\n",
      "Processing index 63...! Done\n",
      "Processing index 64...! Done\n",
      "Processing index 65...! Done\n",
      "Processing index 66...! Done\n",
      "Processing index 67...! Done\n",
      "Processing index 68...! Done\n",
      "Processing index 69...! Done\n",
      "Processing index 70...! "
     ]
    }
   ],
   "source": [
    "predict_textrank = pd.DataFrame()\n",
    "#for i in df.index:\n",
    "for i in df.loc[0:5].index:    \n",
    "    print('Processing index', i, end='...! ')\n",
    "    text = df[\"text\"][i]\n",
    "    ls_judul = preprocess(df[\"judul\"][i]).split()\n",
    "    keyphrases, labels = textrank(text, ls_judul, num_keywords=10)\n",
    "    df_keyphrases = pd.DataFrame(keyphrases, columns=['Keyword', 'Score'])\n",
    "    a = pd.DataFrame(df_keyphrases.Keyword).T.reset_index(drop=True)\n",
    "    b = pd.DataFrame(df_keyphrases.Score).round(3).T.reset_index(drop=True)\n",
    "    df_keyphrases = pd.concat([a, b], axis=1)\n",
    "\n",
    "    # Check if there are missing columns and add them with zero values\n",
    "    missing_columns = 20 - df_keyphrases.shape[1]\n",
    "    for _ in range(missing_columns):\n",
    "        df_keyphrases[df_keyphrases.shape[1]] = 0\n",
    "\n",
    "    df_keyphrases.columns = ['key_1', 'key_2','key_3', 'key_4', 'key_5','key_6', 'key_7', 'key_8','key_9','key_10','score_1', 'score_2','score_3','score_4', 'score_5','score_6','score_7', 'score_8','score_9','score_10'] \n",
    "    predict_textrank = pd.concat([predict_textrank, df_keyphrases], ignore_index=True)\n",
    "    print('Done')\n",
    "predict_textrank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval\n",
    "\n",
    "targets = df[[\"k1\", \"k2\", \"k3\",\"k4\", \"k5\", \"k6\",\"k7\"]].values.tolist()\n",
    "df_targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_1          key_2     key_3     key_4          key_5     key_6  \\\n",
       "0       no_match     full_match  no_match  no_match  partial_match  no_match   \n",
       "1  partial_match  partial_match  no_match  no_match       no_match  no_match   \n",
       "2  partial_match       no_match  no_match  no_match       no_match  no_match   \n",
       "\n",
       "        key_7          key_8       key_9    key_10  flex_recall  flex_prec  \n",
       "0  full_match       no_match    no_match  no_match        0.429        0.3  \n",
       "1  full_match  partial_match  full_match  no_match        0.714        0.5  \n",
       "2    no_match       no_match    no_match  no_match        0.143        0.1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 10\n",
    "predict_textrank_list_10 = predict_textrank[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10']].values.tolist()\n",
    "eval_textrank_10 = eval(predict_textrank_list_10, targets, True).round(3)\n",
    "eval_textrank_10.columns = ['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_10 = eval_textrank_10[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.318\n",
       "precision     0.223\n",
       "F1            0.262"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_10 = eval_textrank_10['flex_recall'].mean()\n",
    "textrank_prec_10 = eval_textrank_10['flex_prec'].mean()\n",
    "textrank_f1_10 = 2 * (textrank_prec_10 * textrank_recall_10) / (textrank_prec_10 + textrank_recall_10)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_10 = pd.DataFrame({'textrank': [textrank_recall_10, textrank_prec_10, textrank_f1_10]}, index=['recall', 'precision', 'F1'])\n",
    "summary_10 = summary_10.round(3)\n",
    "summary_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_1          key_2     key_3     key_4          key_5  \\\n",
       "0       no_match     full_match  no_match  no_match  partial_match   \n",
       "1  partial_match  partial_match  no_match  no_match       no_match   \n",
       "2  partial_match       no_match  no_match  no_match       no_match   \n",
       "\n",
       "   flex_recall  flex_prec  \n",
       "0        0.286        0.4  \n",
       "1        0.286        0.4  \n",
       "2        0.143        0.2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 5\n",
    "predict_textrank_list_5 = predict_textrank[['key_1','key_2','key_3', 'key_4','key_5']].values.tolist()\n",
    "eval_textrank_5 = eval(predict_textrank_list_5, targets, True).round(3)\n",
    "eval_textrank_5.columns = ['key_1','key_2','key_3', 'key_4','key_5','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_5 = eval_textrank_5[['key_1','key_2','key_3', 'key_4','key_5', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.217\n",
       "precision     0.304\n",
       "F1            0.254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_5 = eval_textrank_5['flex_recall'].mean()\n",
    "textrank_prec_5 = eval_textrank_5['flex_prec'].mean()\n",
    "textrank_f1_5 = 2 * (textrank_prec_5 * textrank_recall_5) / (textrank_prec_5 + textrank_recall_5)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_5 = pd.DataFrame({'textrank': [textrank_recall_5, textrank_prec_5, textrank_f1_5]}, index=['recall', 'precision', 'F1'])\n",
    "summary_5 = summary_5.round(3)\n",
    "summary_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_1          key_2     key_3  flex_recall  flex_prec\n",
       "0       no_match     full_match  no_match        0.143      0.333\n",
       "1  partial_match  partial_match  no_match        0.286      0.667\n",
       "2  partial_match       no_match  no_match        0.143      0.333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 3\n",
    "predict_textrank_list_3 = predict_textrank[['key_1','key_2','key_3']].values.tolist()\n",
    "eval_textrank_3 = eval(predict_textrank_list_3, targets, True).round(3)\n",
    "eval_textrank_3.columns = ['key_1', 'key_2','key_3','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_3 = eval_textrank_3[['key_1', 'key_2','key_3', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.156\n",
       "precision     0.365\n",
       "F1            0.219"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_3 = eval_textrank_3['flex_recall'].mean()\n",
    "textrank_prec_3 = eval_textrank_3['flex_prec'].mean()\n",
    "textrank_f1_3 = 2 * (textrank_prec_3 * textrank_recall_3) / (textrank_prec_3 + textrank_recall_3)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_3 = pd.DataFrame({'textrank': [textrank_recall_3, textrank_prec_3, textrank_f1_3]}, index=['recall', 'precision', 'F1'])\n",
    "summary_3 = summary_3.round(3)\n",
    "summary_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>tender</td>\n",
       "      <td>penjelasan</td>\n",
       "      <td>persetujuan</td>\n",
       "      <td>penilaian</td>\n",
       "      <td>usulan</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>kandidat</td>\n",
       "      <td>pengumuman</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>facilities</td>\n",
       "      <td>processing</td>\n",
       "      <td>procedure</td>\n",
       "      <td>coordination</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>acuan</td>\n",
       "      <td>tiung</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>appendix</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>kesepahaman</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>usulan</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>mingguan</td>\n",
       "      <td>offices</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1      key_2       key_3       key_4        key_5         key_6  \\\n",
       "0  personil  pengganti      tender  penjelasan  persetujuan     penilaian   \n",
       "1  template   document  facilities  processing    procedure  coordination   \n",
       "2    kantor    ruangan    appendix    lapangan  kesepahaman        lokasi   \n",
       "\n",
       "         key_7        key_8     key_9      key_10  ...     key_3     key_4  \\\n",
       "0       usulan     diajukan  kandidat  pengumuman  ...  no_match  no_match   \n",
       "1  pengelolaan      exhibit     acuan       tiung  ...  no_match  no_match   \n",
       "2       usulan  klarifikasi  mingguan     offices  ...  no_match  no_match   \n",
       "\n",
       "           key_5     key_6       key_7          key_8       key_9    key_10  \\\n",
       "0  partial_match  no_match  full_match       no_match    no_match  no_match   \n",
       "1       no_match  no_match  full_match  partial_match  full_match  no_match   \n",
       "2       no_match  no_match    no_match       no_match    no_match  no_match   \n",
       "\n",
       "   flex_recall  flex_prec  \n",
       "0        0.429        0.3  \n",
       "1        0.714        0.5  \n",
       "2        0.143        0.1  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_10 = pd.concat([predict_textrank, df_targets, eval_textrank_10], axis=1)\n",
    "predict_textrank_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>tender</td>\n",
       "      <td>penjelasan</td>\n",
       "      <td>persetujuan</td>\n",
       "      <td>penilaian</td>\n",
       "      <td>usulan</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>kandidat</td>\n",
       "      <td>pengumuman</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>facilities</td>\n",
       "      <td>processing</td>\n",
       "      <td>procedure</td>\n",
       "      <td>coordination</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>acuan</td>\n",
       "      <td>tiung</td>\n",
       "      <td>...</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>appendix</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>kesepahaman</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>usulan</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>mingguan</td>\n",
       "      <td>offices</td>\n",
       "      <td>...</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1      key_2       key_3       key_4        key_5         key_6  \\\n",
       "0  personil  pengganti      tender  penjelasan  persetujuan     penilaian   \n",
       "1  template   document  facilities  processing    procedure  coordination   \n",
       "2    kantor    ruangan    appendix    lapangan  kesepahaman        lokasi   \n",
       "\n",
       "         key_7        key_8     key_9      key_10  ...                     4  \\\n",
       "0       usulan     diajukan  kandidat  pengumuman  ...                   NaN   \n",
       "1  pengelolaan      exhibit     acuan       tiung  ...               dokumen   \n",
       "2       usulan  klarifikasi  mingguan     offices  ...  services for company   \n",
       "\n",
       "           5    6          key_1          key_2     key_3     key_4  \\\n",
       "0        NaN  NaN       no_match     full_match  no_match  no_match   \n",
       "1        NaN  NaN  partial_match  partial_match  no_match  no_match   \n",
       "2  exhibit a  NaN  partial_match       no_match  no_match  no_match   \n",
       "\n",
       "           key_5  flex_recall  flex_prec  \n",
       "0  partial_match        0.286        0.4  \n",
       "1       no_match        0.286        0.4  \n",
       "2       no_match        0.143        0.2  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_5 = pd.concat([predict_textrank, df_targets, eval_textrank_5], axis=1)\n",
    "predict_textrank_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>tender</td>\n",
       "      <td>penjelasan</td>\n",
       "      <td>persetujuan</td>\n",
       "      <td>penilaian</td>\n",
       "      <td>usulan</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>kandidat</td>\n",
       "      <td>pengumuman</td>\n",
       "      <td>...</td>\n",
       "      <td>usulan</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>facilities</td>\n",
       "      <td>processing</td>\n",
       "      <td>procedure</td>\n",
       "      <td>coordination</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>acuan</td>\n",
       "      <td>tiung</td>\n",
       "      <td>...</td>\n",
       "      <td>acuan</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>appendix</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>kesepahaman</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>usulan</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>mingguan</td>\n",
       "      <td>offices</td>\n",
       "      <td>...</td>\n",
       "      <td>lingkup kerja</td>\n",
       "      <td>akomodasi</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1      key_2       key_3       key_4        key_5         key_6  \\\n",
       "0  personil  pengganti      tender  penjelasan  persetujuan     penilaian   \n",
       "1  template   document  facilities  processing    procedure  coordination   \n",
       "2    kantor    ruangan    appendix    lapangan  kesepahaman        lokasi   \n",
       "\n",
       "         key_7        key_8     key_9      key_10  ...              2  \\\n",
       "0       usulan     diajukan  kandidat  pengumuman  ...         usulan   \n",
       "1  pengelolaan      exhibit     acuan       tiung  ...          acuan   \n",
       "2       usulan  klarifikasi  mingguan     offices  ...  lingkup kerja   \n",
       "\n",
       "             3                     4          5    6          key_1  \\\n",
       "0    pengganti                   NaN        NaN  NaN       no_match   \n",
       "1  pengelolaan               dokumen        NaN  NaN  partial_match   \n",
       "2    akomodasi  services for company  exhibit a  NaN  partial_match   \n",
       "\n",
       "           key_2     key_3  flex_recall  flex_prec  \n",
       "0     full_match  no_match        0.143      0.333  \n",
       "1  partial_match  no_match        0.286      0.667  \n",
       "2       no_match  no_match        0.143      0.333  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_3 = pd.concat([predict_textrank, df_targets, eval_textrank_3], axis=1)\n",
    "predict_textrank_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def write_excel(df, sheet_name, filename):\n",
    "    \"\"\"\n",
    "    Writes the given dataframe to an excel file with the given filename and sheet name.\n",
    "    If the sheet already exists in the file, the data in the sheet will be overwritten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "            if sheet_name in writer.book.sheetnames:\n",
    "                # If sheet already exists, remove it\n",
    "                sheet = writer.book[sheet_name]\n",
    "                writer.book.remove(sheet)\n",
    "\n",
    "            # Write the dataframe to the excel file\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to excel file\n",
    "#from utils import write_excel\n",
    "\n",
    "sheet_name_10 = '16b_TR_w2v_lg_pos_posisi_wfrase_10'\n",
    "sheet_name_5 = '16b_TR_w2v_lg_pos_posisi_wfrase_5'\n",
    "sheet_name_3 = '16b_TR_w2v_lg_pos_posisi_wfrase_3'\n",
    "\n",
    "output_file = '16b_TR_w2v_lg_pos_posisi_wfrase.xlsx'\n",
    "write_excel(predict_textrank_10, sheet_name_10, output_file)\n",
    "write_excel(predict_textrank_5, sheet_name_5, output_file)\n",
    "write_excel(predict_textrank_3, sheet_name_3, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
