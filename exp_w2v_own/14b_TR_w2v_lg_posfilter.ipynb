{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"data/dataset_ekstraksi_r30_lg.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "'''\n",
    "stopwords tidak masuk dalam preprocessing\n",
    "'''\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df['text'].apply(preprocess)\n",
    "df[\"judul\"] = df[\"judul\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_path = os.path.join(repo_root, \"notebooks/stopwords_tuning/all_stop_words.txt\")\n",
    "with open(stopwords_path, 'r') as file:\n",
    "    stopwords = set(file.read().strip().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nlp_id_local.tokenizer import PhraseTokenizer \n",
    "from nlp_id_local.postag import PosTag\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def generate_ngrams(words, n=2):\n",
    "    \"\"\"Generate ngrams from a list of words.\"\"\"\n",
    "    return [\" \".join(gram) for gram in ngrams(words, n)]\n",
    "\n",
    "def detect_bigram(text):\n",
    "    \n",
    "    tokenizer = PhraseTokenizer()\n",
    "    phrases = tokenizer.tokenize(text)\n",
    "    # Include only bigrams whose individual words are in available_tokens\n",
    "    bigrams_only = [phrase for phrase in phrases if phrase.count(\" \") == 1]\n",
    "\n",
    "    return bigrams_only\n",
    "\n",
    "def detect_trigram(text):\n",
    "\n",
    "    tokenizer = PhraseTokenizer()\n",
    "    phrases = tokenizer.tokenize(text)\n",
    "    # Include only trigrams whose individual words are in available_tokens\n",
    "    trigrams_only = [phrase for phrase in phrases if phrase.count(\" \") == 2 ]\n",
    "\n",
    "    return trigrams_only\n",
    "\n",
    "def detect_all_tokens(text):\n",
    "    unigrams = [word for word in text.split()]\n",
    "    bigrams = detect_bigram(text)\n",
    "    trigrams = detect_trigram(text)\n",
    "    \n",
    "    # Combine unigrams, filtered bigrams, and filtered trigrams\n",
    "    all_tokens = unigrams + bigrams + trigrams\n",
    "\n",
    "    return all_tokens\n",
    "\n",
    "def visualize_graph(G, labels):\n",
    "    # Remove self-loops (edges that connect a node to itself)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    #nx.draw(G, pos=pos, with_labels=False, font_weight=\"bold\", node_size=5000, node_color='skyblue')\n",
    "    nx.draw(G, pos=pos, with_labels=False, font_weight=\"bold\")\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def load_word2vec_model(model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"The provided Word2Vec model path does not exist: {model_path}\")\n",
    "    \n",
    "    w2v_model = Word2Vec.load(model_path) \n",
    "    available_tokens = set(w2v_model.wv.key_to_index)\n",
    "    \n",
    "    return w2v_model, available_tokens\n",
    "\n",
    "# Example usage\n",
    "model_path = os.path.join(repo_root, \"models/w2v_200/idwiki_word2vec_200_new_lower.model\")\n",
    "w2v_model, available_tokens = load_word2vec_model(model_path)\n",
    "\n",
    "# Show a sample of available tokens\n",
    "sample_tokens = list(available_tokens)[:5]\n",
    "sample_tokens\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine_similarity(w1, w2, w2v_model):\n",
    "    if w1 not in w2v_model.wv or w2 not in w2v_model.wv:\n",
    "        return 0\n",
    "    vec1 = w2v_model.wv[w1]\n",
    "    vec2 = w2v_model.wv[w2]\n",
    "    similarity = cosine_similarity([vec1], [vec2])[0][0]\n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORATORY PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pertokoan', 'seaktif', 'supersonic', 'kremenchuk', 'erazem']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "model_path = os.path.join(repo_root, \"models/w2v_200/idwiki_word2vec_200_new_lower.model\")\n",
    "w2v_model, available_tokens = load_word2vec_model(model_path)\n",
    "\n",
    "# Show a sample of available tokens\n",
    "sample_tokens = list(available_tokens)[:5]\n",
    "sample_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(repo_root, \"notebooks/nlp-id_retraining/train_tuned.pkl\")\n",
    "\n",
    "def get_unique_tokens_pos(all_tokens, model_path):\n",
    "    \"\"\"\n",
    "    Get unique POS tags for tokens.\n",
    "    \"\"\"\n",
    "    postagger = PosTag(model_path)\n",
    "    pos_tokens = []\n",
    "    seen_tokens = set()\n",
    "    \n",
    "    for token in all_tokens:\n",
    "        if token not in seen_tokens:\n",
    "            seen_tokens.add(token)\n",
    "            tokens_pos = postagger.get_phrase_tag(token)\n",
    "            pos_tokens.append(tokens_pos)\n",
    "    return pos_tokens\n",
    "\n",
    "def flatten_list_of_lists(list_of_lists):\n",
    "    \"\"\"\n",
    "    Flatten a list of lists into a single list.\n",
    "    \"\"\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def filter_tokens_by_pos(flat_tokens, pos_filters):\n",
    "    \"\"\"\n",
    "    Filter tokens based on their POS tags and ensure they're unique.\n",
    "    \"\"\"\n",
    "    seen_tokens = set()\n",
    "    return [token[0] for token in flat_tokens if token[1] in pos_filters and not (token[0] in seen_tokens or seen_tokens.add(token[0]))]\n",
    "\n",
    "def get_phrase_embedding(phrase, w2v_model):\n",
    "    \"\"\"Get the averaged word embedding for a phrase.\"\"\"\n",
    "    words = phrase.split()\n",
    "    embeddings = [w2v_model.wv[word] for word in words if word in w2v_model.wv.key_to_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank(text, num_keywords=10):\n",
    "    # Tokenize the text\n",
    "    words = detect_all_tokens(text)\n",
    "    # Load stopwords for the specified language\n",
    "    stop_words = stopwords\n",
    "    \n",
    "    # Filter out stopwords and punctuation\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    # Filter tokens only for selected POS\n",
    "    pos_tokens = get_unique_tokens_pos(words, model_path)\n",
    "    flat_pos_tokens = flatten_list_of_lists(pos_tokens)\n",
    "    selected_pos = {'NN', 'NNP', 'VB', 'NP', 'VP'} # FW di exclude\n",
    "    filtered_tokens = filter_tokens_by_pos(flat_pos_tokens, selected_pos)\n",
    "\n",
    "    # Get embeddings for each token (averaging word embeddings for bigrams/trigrams)\n",
    "    token_embeddings = [get_phrase_embedding(token, w2v_model) for token in filtered_tokens]\n",
    "    \n",
    "    # Filter out tokens that don't have embeddings\n",
    "    tokens, embeddings = zip(*[(token, emb) for token, emb in zip(filtered_tokens, token_embeddings) if emb is not None])\n",
    "\n",
    "    # Compute the cosine similarity between token embeddings\n",
    "    cosine_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "    # Create a mapping from tokens to indices\n",
    "    token_to_index = {token: idx for idx, token in enumerate(tokens)}\n",
    "\n",
    "    # Build a co-occurrence matrix\n",
    "    co_occurrence = defaultdict(int)\n",
    "    window_size = 3\n",
    "    for i in range(len(words) - window_size + 1):\n",
    "        window = words[i:i+window_size]\n",
    "        for j in range(window_size):\n",
    "            for k in range(j+1, window_size):\n",
    "                w1, w2 = sorted([window[j], window[k]])\n",
    "                if w1 != w2:\n",
    "                    co_occurrence[(w1, w2)] += 1\n",
    "    \n",
    "    # Build a graph\n",
    "    G = nx.Graph()\n",
    "    for (w1, w2), weight1 in co_occurrence.items():\n",
    "        # Convert w1 and w2 to indices\n",
    "        idx1 = token_to_index.get(w1)\n",
    "        idx2 = token_to_index.get(w2)\n",
    "        if idx1 is not None and idx2 is not None:\n",
    "            # Look up the cosine similarity value\n",
    "            weight2 = cosine_matrix[idx1][idx2]\n",
    "            weight3 = weight1 * weight2\n",
    "            G.add_edge(w1, w2, weight=weight3)\n",
    "    \n",
    "    # Compute TextRank scores\n",
    "    scores = nx.pagerank(G)\n",
    "    \n",
    "    # Prepare labels\n",
    "    labels = {node: f'{node}\\n({score:.2f})' for node, score in scores.items()}\n",
    "\n",
    "    # Sort words by scores\n",
    "    ranked_words = sorted(((score, word) for word, score in scores.items()), reverse=True)\n",
    "    \n",
    "    # Extract the top keywords\n",
    "    keywords = [word for score, word in ranked_words[:num_keywords]]\n",
    "\n",
    "    keyphrases_with_scores = []\n",
    "    seen_tokens = set()  # Set to keep track of tokens that have already been added\n",
    "\n",
    "    for score, token in ranked_words:\n",
    "        if token not in seen_tokens:\n",
    "            keyphrases_with_scores.append((token, score))\n",
    "            seen_tokens.add(token)  # Mark the token as seen\n",
    "            if len(keyphrases_with_scores) >= num_keywords:\n",
    "                break \n",
    "    \n",
    "    return keyphrases_with_scores, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITERASI UNTUK ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index 0...! Done\n",
      "Processing index 1...! Done\n",
      "Processing index 2...! "
     ]
    },
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing index\u001b[39m\u001b[39m'\u001b[39m, i, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m...! \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m text \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m][i]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m keyphrases, labels \u001b[39m=\u001b[39m textrank(text, num_keywords\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_keyphrases \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(keyphrases, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mKeyword\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m a \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(df_keyphrases\u001b[39m.\u001b[39mKeyword)\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         G\u001b[39m.\u001b[39madd_edge(w1, w2, weight\u001b[39m=\u001b[39mweight3)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Compute TextRank scores\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m scores \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39;49mpagerank(G)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Prepare labels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jim/Documents/GitHub/kw_ina_extraction/exp_w2v_own/14b_TR_w2v_lg_posfilter.ipynb#X44sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m labels \u001b[39m=\u001b[39m {node: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m node, score \u001b[39min\u001b[39;00m scores\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/anaconda3/envs/kw_ina/lib/python3.11/site-packages/networkx/classes/backends.py:148\u001b[0m, in \u001b[0;36m_dispatch.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m             \u001b[39mraise\u001b[39;00m NetworkXNotImplemented(\n\u001b[1;32m    146\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not implemented by \u001b[39m\u001b[39m{\u001b[39;00mplugin_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m             )\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/kw_ina/lib/python3.11/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:110\u001b[0m, in \u001b[0;36mpagerank\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m@nx\u001b[39m\u001b[39m.\u001b[39m_dispatch\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpagerank\u001b[39m(\n\u001b[1;32m     11\u001b[0m     G,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     dangling\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the PageRank of the nodes in the graph.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[39m    PageRank computes a ranking of the nodes in the graph G based on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m _pagerank_scipy(\n\u001b[1;32m    111\u001b[0m         G, alpha, personalization, max_iter, tol, nstart, weight, dangling\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/kw_ina/lib/python3.11/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:500\u001b[0m, in \u001b[0;36m_pagerank_scipy\u001b[0;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[39mif\u001b[39;00m err \u001b[39m<\u001b[39m N \u001b[39m*\u001b[39m tol:\n\u001b[1;32m    499\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(nodelist, \u001b[39mmap\u001b[39m(\u001b[39mfloat\u001b[39m, x)))\n\u001b[0;32m--> 500\u001b[0m \u001b[39mraise\u001b[39;00m nx\u001b[39m.\u001b[39mPowerIterationFailedConvergence(max_iter)\n",
      "\u001b[0;31mPowerIterationFailedConvergence\u001b[0m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "predict_textrank = pd.DataFrame()\n",
    "#for i in df.index:\n",
    "for i in df.loc[:3].index:    \n",
    "    print('Processing index', i, end='...! ')\n",
    "    text = df[\"text\"][i]\n",
    "    keyphrases, labels = textrank(text, num_keywords=10)\n",
    "    df_keyphrases = pd.DataFrame(keyphrases, columns=['Keyword', 'Score'])\n",
    "    a = pd.DataFrame(df_keyphrases.Keyword).T.reset_index(drop=True)\n",
    "    b = pd.DataFrame(df_keyphrases.Score).round(3).T.reset_index(drop=True)\n",
    "    df_keyphrases = pd.concat([a, b], axis=1)\n",
    "\n",
    "    # Check if there are missing columns and add them with zero values\n",
    "    missing_columns = 20 - df_keyphrases.shape[1]\n",
    "    for _ in range(missing_columns):\n",
    "        df_keyphrases[df_keyphrases.shape[1]] = 0\n",
    "\n",
    "    df_keyphrases.columns = ['key_1', 'key_2','key_3', 'key_4', 'key_5','key_6', 'key_7', 'key_8','key_9','key_10','score_1', 'score_2','score_3','score_4', 'score_5','score_6','score_7', 'score_8','score_9','score_10'] \n",
    "    predict_textrank = pd.concat([predict_textrank, df_keyphrases], ignore_index=True)\n",
    "    print('Done')\n",
    "predict_textrank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval\n",
    "\n",
    "targets = df[[\"k1\", \"k2\", \"k3\",\"k4\", \"k5\", \"k6\",\"k7\"]].values.tolist()\n",
    "df_targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_1          key_2     key_3     key_4          key_5     key_6  \\\n",
       "0       no_match     full_match  no_match  no_match  partial_match  no_match   \n",
       "1  partial_match  partial_match  no_match  no_match       no_match  no_match   \n",
       "2  partial_match       no_match  no_match  no_match       no_match  no_match   \n",
       "\n",
       "        key_7          key_8       key_9    key_10  flex_recall  flex_prec  \n",
       "0  full_match       no_match    no_match  no_match        0.429        0.3  \n",
       "1  full_match  partial_match  full_match  no_match        0.714        0.5  \n",
       "2    no_match       no_match    no_match  no_match        0.143        0.1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 10\n",
    "predict_textrank_list_10 = predict_textrank[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10']].values.tolist()\n",
    "eval_textrank_10 = eval(predict_textrank_list_10, targets, True).round(3)\n",
    "eval_textrank_10.columns = ['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_10 = eval_textrank_10[['key_1','key_2','key_3', 'key_4','key_5','key_6', 'key_7','key_8','key_9', 'key_10', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.318\n",
       "precision     0.223\n",
       "F1            0.262"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_10 = eval_textrank_10['flex_recall'].mean()\n",
    "textrank_prec_10 = eval_textrank_10['flex_prec'].mean()\n",
    "textrank_f1_10 = 2 * (textrank_prec_10 * textrank_recall_10) / (textrank_prec_10 + textrank_recall_10)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_10 = pd.DataFrame({'textrank': [textrank_recall_10, textrank_prec_10, textrank_f1_10]}, index=['recall', 'precision', 'F1'])\n",
    "summary_10 = summary_10.round(3)\n",
    "summary_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_1          key_2     key_3     key_4          key_5  \\\n",
       "0       no_match     full_match  no_match  no_match  partial_match   \n",
       "1  partial_match  partial_match  no_match  no_match       no_match   \n",
       "2  partial_match       no_match  no_match  no_match       no_match   \n",
       "\n",
       "   flex_recall  flex_prec  \n",
       "0        0.286        0.4  \n",
       "1        0.286        0.4  \n",
       "2        0.143        0.2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 5\n",
    "predict_textrank_list_5 = predict_textrank[['key_1','key_2','key_3', 'key_4','key_5']].values.tolist()\n",
    "eval_textrank_5 = eval(predict_textrank_list_5, targets, True).round(3)\n",
    "eval_textrank_5.columns = ['key_1','key_2','key_3', 'key_4','key_5','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_5 = eval_textrank_5[['key_1','key_2','key_3', 'key_4','key_5', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.217\n",
       "precision     0.304\n",
       "F1            0.254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_5 = eval_textrank_5['flex_recall'].mean()\n",
    "textrank_prec_5 = eval_textrank_5['flex_prec'].mean()\n",
    "textrank_f1_5 = 2 * (textrank_prec_5 * textrank_recall_5) / (textrank_prec_5 + textrank_recall_5)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_5 = pd.DataFrame({'textrank': [textrank_recall_5, textrank_prec_5, textrank_f1_5]}, index=['recall', 'precision', 'F1'])\n",
    "summary_5 = summary_5.round(3)\n",
    "summary_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key_1          key_2     key_3  flex_recall  flex_prec\n",
       "0       no_match     full_match  no_match        0.143      0.333\n",
       "1  partial_match  partial_match  no_match        0.286      0.667\n",
       "2  partial_match       no_match  no_match        0.143      0.333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank top 3\n",
    "predict_textrank_list_3 = predict_textrank[['key_1','key_2','key_3']].values.tolist()\n",
    "eval_textrank_3 = eval(predict_textrank_list_3, targets, True).round(3)\n",
    "eval_textrank_3.columns = ['key_1', 'key_2','key_3','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank_3 = eval_textrank_3[['key_1', 'key_2','key_3', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.156\n",
       "precision     0.365\n",
       "F1            0.219"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall_3 = eval_textrank_3['flex_recall'].mean()\n",
    "textrank_prec_3 = eval_textrank_3['flex_prec'].mean()\n",
    "textrank_f1_3 = 2 * (textrank_prec_3 * textrank_recall_3) / (textrank_prec_3 + textrank_recall_3)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary_3 = pd.DataFrame({'textrank': [textrank_recall_3, textrank_prec_3, textrank_f1_3]}, index=['recall', 'precision', 'F1'])\n",
    "summary_3 = summary_3.round(3)\n",
    "summary_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>tender</td>\n",
       "      <td>penjelasan</td>\n",
       "      <td>persetujuan</td>\n",
       "      <td>penilaian</td>\n",
       "      <td>usulan</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>kandidat</td>\n",
       "      <td>pengumuman</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>facilities</td>\n",
       "      <td>processing</td>\n",
       "      <td>procedure</td>\n",
       "      <td>coordination</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>acuan</td>\n",
       "      <td>tiung</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>appendix</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>kesepahaman</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>usulan</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>mingguan</td>\n",
       "      <td>offices</td>\n",
       "      <td>...</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1      key_2       key_3       key_4        key_5         key_6  \\\n",
       "0  personil  pengganti      tender  penjelasan  persetujuan     penilaian   \n",
       "1  template   document  facilities  processing    procedure  coordination   \n",
       "2    kantor    ruangan    appendix    lapangan  kesepahaman        lokasi   \n",
       "\n",
       "         key_7        key_8     key_9      key_10  ...     key_3     key_4  \\\n",
       "0       usulan     diajukan  kandidat  pengumuman  ...  no_match  no_match   \n",
       "1  pengelolaan      exhibit     acuan       tiung  ...  no_match  no_match   \n",
       "2       usulan  klarifikasi  mingguan     offices  ...  no_match  no_match   \n",
       "\n",
       "           key_5     key_6       key_7          key_8       key_9    key_10  \\\n",
       "0  partial_match  no_match  full_match       no_match    no_match  no_match   \n",
       "1       no_match  no_match  full_match  partial_match  full_match  no_match   \n",
       "2       no_match  no_match    no_match       no_match    no_match  no_match   \n",
       "\n",
       "   flex_recall  flex_prec  \n",
       "0        0.429        0.3  \n",
       "1        0.714        0.5  \n",
       "2        0.143        0.1  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_10 = pd.concat([predict_textrank, df_targets, eval_textrank_10], axis=1)\n",
    "predict_textrank_10.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>tender</td>\n",
       "      <td>penjelasan</td>\n",
       "      <td>persetujuan</td>\n",
       "      <td>penilaian</td>\n",
       "      <td>usulan</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>kandidat</td>\n",
       "      <td>pengumuman</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>facilities</td>\n",
       "      <td>processing</td>\n",
       "      <td>procedure</td>\n",
       "      <td>coordination</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>acuan</td>\n",
       "      <td>tiung</td>\n",
       "      <td>...</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>appendix</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>kesepahaman</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>usulan</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>mingguan</td>\n",
       "      <td>offices</td>\n",
       "      <td>...</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1      key_2       key_3       key_4        key_5         key_6  \\\n",
       "0  personil  pengganti      tender  penjelasan  persetujuan     penilaian   \n",
       "1  template   document  facilities  processing    procedure  coordination   \n",
       "2    kantor    ruangan    appendix    lapangan  kesepahaman        lokasi   \n",
       "\n",
       "         key_7        key_8     key_9      key_10  ...                     4  \\\n",
       "0       usulan     diajukan  kandidat  pengumuman  ...                   NaN   \n",
       "1  pengelolaan      exhibit     acuan       tiung  ...               dokumen   \n",
       "2       usulan  klarifikasi  mingguan     offices  ...  services for company   \n",
       "\n",
       "           5    6          key_1          key_2     key_3     key_4  \\\n",
       "0        NaN  NaN       no_match     full_match  no_match  no_match   \n",
       "1        NaN  NaN  partial_match  partial_match  no_match  no_match   \n",
       "2  exhibit a  NaN  partial_match       no_match  no_match  no_match   \n",
       "\n",
       "           key_5  flex_recall  flex_prec  \n",
       "0  partial_match        0.286        0.4  \n",
       "1       no_match        0.286        0.4  \n",
       "2       no_match        0.143        0.2  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_5 = pd.concat([predict_textrank, df_targets, eval_textrank_5], axis=1)\n",
    "predict_textrank_5.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>...</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>tender</td>\n",
       "      <td>penjelasan</td>\n",
       "      <td>persetujuan</td>\n",
       "      <td>penilaian</td>\n",
       "      <td>usulan</td>\n",
       "      <td>diajukan</td>\n",
       "      <td>kandidat</td>\n",
       "      <td>pengumuman</td>\n",
       "      <td>...</td>\n",
       "      <td>usulan</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template</td>\n",
       "      <td>document</td>\n",
       "      <td>facilities</td>\n",
       "      <td>processing</td>\n",
       "      <td>procedure</td>\n",
       "      <td>coordination</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>exhibit</td>\n",
       "      <td>acuan</td>\n",
       "      <td>tiung</td>\n",
       "      <td>...</td>\n",
       "      <td>acuan</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kantor</td>\n",
       "      <td>ruangan</td>\n",
       "      <td>appendix</td>\n",
       "      <td>lapangan</td>\n",
       "      <td>kesepahaman</td>\n",
       "      <td>lokasi</td>\n",
       "      <td>usulan</td>\n",
       "      <td>klarifikasi</td>\n",
       "      <td>mingguan</td>\n",
       "      <td>offices</td>\n",
       "      <td>...</td>\n",
       "      <td>lingkup kerja</td>\n",
       "      <td>akomodasi</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1      key_2       key_3       key_4        key_5         key_6  \\\n",
       "0  personil  pengganti      tender  penjelasan  persetujuan     penilaian   \n",
       "1  template   document  facilities  processing    procedure  coordination   \n",
       "2    kantor    ruangan    appendix    lapangan  kesepahaman        lokasi   \n",
       "\n",
       "         key_7        key_8     key_9      key_10  ...              2  \\\n",
       "0       usulan     diajukan  kandidat  pengumuman  ...         usulan   \n",
       "1  pengelolaan      exhibit     acuan       tiung  ...          acuan   \n",
       "2       usulan  klarifikasi  mingguan     offices  ...  lingkup kerja   \n",
       "\n",
       "             3                     4          5    6          key_1  \\\n",
       "0    pengganti                   NaN        NaN  NaN       no_match   \n",
       "1  pengelolaan               dokumen        NaN  NaN  partial_match   \n",
       "2    akomodasi  services for company  exhibit a  NaN  partial_match   \n",
       "\n",
       "           key_2     key_3  flex_recall  flex_prec  \n",
       "0     full_match  no_match        0.143      0.333  \n",
       "1  partial_match  no_match        0.286      0.667  \n",
       "2       no_match  no_match        0.143      0.333  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank_3 = pd.concat([predict_textrank, df_targets, eval_textrank_3], axis=1)\n",
    "predict_textrank_3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "def write_excel(df, sheet_name, filename):\n",
    "    \"\"\"\n",
    "    Writes the given dataframe to an excel file with the given filename and sheet name.\n",
    "    If the sheet already exists in the file, the data in the sheet will be overwritten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to load the existing workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='a') as writer:\n",
    "            if sheet_name in writer.book.sheetnames:\n",
    "                # If sheet already exists, remove it\n",
    "                sheet = writer.book[sheet_name]\n",
    "                writer.book.remove(sheet)\n",
    "\n",
    "            # Write the dataframe to the excel file\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        # If the file doesn't exist, create a new workbook\n",
    "        with pd.ExcelWriter(filename, engine='openpyxl', mode='w') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to excel file\n",
    "#from utils import write_excel\n",
    "\n",
    "sheet_name_10 = '13b_TR_w2v_lg_combined_10'\n",
    "sheet_name_5 = '13b_TR_w2v_lg_combined_5'\n",
    "sheet_name_3 = '13b_TR_w2v_lg_combined_3'\n",
    "\n",
    "output_file = '13b_TR_w2v_lg_combined.xlsx'\n",
    "write_excel(predict_textrank_10, sheet_name_10, output_file)\n",
    "write_excel(predict_textrank_5, sheet_name_5, output_file)\n",
    "write_excel(predict_textrank_3, sheet_name_3, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
