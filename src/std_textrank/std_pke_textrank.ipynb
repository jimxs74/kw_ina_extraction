{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"notebooks/postager_nlp-id/dataset_ekstraksi_r29_pos.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df_pos = df['pos_sentence_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TextRank' from 'utils' (/Users/jim/Documents/GitHub/kw_ina_extraction/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m TextRank\n\u001b[1;32m      3\u001b[0m pos \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mNN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mNP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFW\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m      4\u001b[0m \u001b[39m# 1. create a TextRank extractor.\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'TextRank' from 'utils' (/Users/jim/Documents/GitHub/kw_ina_extraction/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from utils import TextRank\n",
    "\n",
    "pos = {'NN', 'VP', 'NP', 'FW'}\n",
    "# 1. create a TextRank extractor.\n",
    "extractor = TextRank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Text 0..! Done\n",
      "Processing Text 1..! Done\n",
      "Processing Text 2..! Done\n",
      "Processing Text 3..! Done\n",
      "Processing Text 4..! Done\n",
      "Processing Text 5..! Done\n",
      "Processing Text 6..! Done\n",
      "Processing Text 7..! Done\n",
      "Processing Text 8..! Done\n",
      "Processing Text 9..! Done\n",
      "Processing Text 10..! Done\n",
      "Processing Text 11..! Done\n",
      "Processing Text 12..! Done\n",
      "Processing Text 13..! Done\n",
      "Processing Text 14..! Done\n",
      "Processing Text 15..! Done\n",
      "Processing Text 16..! Done\n",
      "Processing Text 17..! Done\n",
      "Processing Text 18..! Done\n",
      "Processing Text 19..! Done\n",
      "Processing Text 20..! Done\n",
      "Processing Text 21..! Done\n",
      "Processing Text 22..! Done\n",
      "Processing Text 23..! Done\n",
      "Processing Text 24..! Done\n",
      "Processing Text 25..! Done\n",
      "Processing Text 26..! Done\n",
      "Processing Text 27..! Done\n",
      "Processing Text 28..! Done\n"
     ]
    }
   ],
   "source": [
    "import ast \n",
    "\n",
    "df_keyphrases = pd.DataFrame(columns=['key_1', 'val_1', 'key_2', 'val_2', 'key_3', 'val_3'])\n",
    "\n",
    "for i in range(len(df_pos)):\n",
    "    try:\n",
    "        text = df_pos[i]\n",
    "        print('Processing Text', i, end='..! ')\n",
    "        text1 = ast.literal_eval(text)\n",
    "        extractor.load_document(input=text1)\n",
    "        keyphrase = extractor.candidate_weighting_ia()\n",
    "\n",
    "        # Separate the key and value elements into separate lists\n",
    "        keys = [item[0] for item in keyphrase]\n",
    "        values = [item[1] for item in keyphrase]\n",
    "\n",
    "        # Create a dictionary with the keys and values\n",
    "        data = {\n",
    "            'key_1': [keys[0]],\n",
    "            'val_1': [values[0]],\n",
    "            'key_2': [keys[1]],\n",
    "            'val_2': [values[1]],\n",
    "            'key_3': [keys[2]],\n",
    "            'val_3': [values[2]],\n",
    "        }\n",
    "        df_keyphrase = pd.DataFrame(data)\n",
    "        print('Done')\n",
    "    except Exception as e:\n",
    "        print('Error on text', i)\n",
    "        data = {\n",
    "            'key_1': ['na'],\n",
    "            'val_1': [0],\n",
    "            'key_2': ['na'],\n",
    "            'val_2': [0],\n",
    "            'key_3': ['na'],\n",
    "            'val_3': [0],\n",
    "        }\n",
    "        df_keyphrase = pd.DataFrame(data)\n",
    "    # Concatenate df_keyphrase with df_keyphrases\n",
    "    df_keyphrases = pd.concat([df_keyphrases, df_keyphrase], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add df_keyphrases ke file excel dataset_ekstraksi_r30.xlsx\n",
    "result_df = pd.concat([df, df_keyphrases], axis=1)\n",
    "\n",
    "# simpan dalam dataset\n",
    "output_file = 'std_pke_textrank.xlsx'\n",
    "result_df.to_excel(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
