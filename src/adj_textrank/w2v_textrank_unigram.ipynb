{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine PKE textrank and word2vec - unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. rutin1 import module\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. rutin2 membuat syspath ke root utk aktifkan __init__.py\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "sys.path.append(repo_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. rutin3 Load the dataset\n",
    "dataset_path = os.path.join(repo_root, \"notebooks/postager_nlp-id/dataset_ekstraksi_r29_pos_sm.xlsx\")\n",
    "df = pd.read_excel(dataset_path)\n",
    "df[\"text\"] = df[\"judul\"] +\". \"+ df[\"isi\"]\n",
    "df_pos = df['pos_sentence_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "import re\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemover, ArrayDictionary\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    stopwords_path = os.path.join(repo_root, \"data/all_stop_words.txt\")\n",
    "    with open(stopwords_path, 'r') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "\n",
    "    dictionary = ArrayDictionary(stopwords)\n",
    "    str = StopWordRemover(dictionary)\n",
    "    text = str.remove(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "df['preprocessed_text'] = df['text'].apply(preprocess)\n",
    "df_tr = df['preprocessed_text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "\n",
    "def extract_keyphrases_with_embeddings(text, w2v_model):\n",
    "    # Get words that have embeddings\n",
    "    words = [word for word in text.split() if word in w2v_model.wv.key_to_index]\n",
    "    word_embeddings = [w2v_model.wv[word] for word in words]\n",
    "\n",
    "    # If no word embeddings are present, return an empty list\n",
    "    if not word_embeddings:\n",
    "        return []\n",
    "    \n",
    "    # Compute the cosine similarity between word embeddings\n",
    "    cosine_matrix = cosine_similarity(word_embeddings)\n",
    "    \n",
    "    # Create a graph and connect words with high similarity\n",
    "    G = nx.Graph()\n",
    "    for i in range(len(words)):\n",
    "        for j in range(len(words)):\n",
    "            if cosine_matrix[i][j] > 0.5:  # This threshold can be adjusted\n",
    "                G.add_edge(words[i], words[j], weight=cosine_matrix[i][j])\n",
    "    \n",
    "    # Compute the PageRank scores to rank the words\n",
    "    scores = nx.pagerank(G)\n",
    "\n",
    "    # Extract top N keyphrases along with their scores\n",
    "    ranked_words = sorted(((scores[word], word) for word in words if word in scores), reverse=True)\n",
    "    keyphrases_with_scores = [(word, score) for score, word in ranked_words[:3]]\n",
    "\n",
    "    return keyphrases_with_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_path = os.path.join(repo_root, \"models/w2v/idwiki_word2vec_100_new_lower.model\")\n",
    "w2v_model = Word2Vec.load(w2v_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('facilities', 0.06241239526183723), ('processing', 0.06168987817329495), ('document', 0.05590062009264529), ('document', 0.05590062009264529), ('procedure', 0.055817361636743196), ('tiung', 0.05263157894736842), ('project', 0.05263157894736842), ('perhatiannya', 0.05263157894736842), ('pengelolaan', 0.05263157894736842), ('pada', 0.05263157894736842)]\n"
     ]
    }
   ],
   "source": [
    "# Assuming w2v_model is your loaded Word2Vec model\n",
    "text = df_tr[1]\n",
    "keyphrases = extract_keyphrases_with_embeddings(text, w2v_model)\n",
    "print(keyphrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multitext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usulan</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>personil</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>personil</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tiung</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instrument</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Keyword  Score\n",
       "0      usulan    0.5\n",
       "1    personil    0.5\n",
       "2    personil    0.5\n",
       "3       tiung    1.0\n",
       "4  instrument    1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df_pos is your dataframe with texts\n",
    "results = []\n",
    "\n",
    "# Iterate over the dataframe\n",
    "for text in df_pos:\n",
    "    keyphrases_with_scores = extract_keyphrases_with_embeddings(text, w2v_model)\n",
    "    results.extend(keyphrases_with_scores)\n",
    "\n",
    "# Convert the results to a dataframe\n",
    "predict_textrank = pd.DataFrame(results, columns=['Keyword', 'Score'])\n",
    "predict_textrank.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kw_ina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
