{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemover, ArrayDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning paramater\n",
    "tuning_multiplier = 1  #aktor pengali dari score jika kata tersebut merupakan frase. default = 1 (perlu variasi 0.6 - 0.75)\n",
    "tuning_f_phrase = 3  #score minimum utk bisa disebut frase\n",
    "m_prediksi = 3  #jumlah top -n keyword prediksi\n",
    "n_top_phrase = 3   #jumlah frase yg akan di cari dalam fungsi get_top_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "def preprocess(text):\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    text = text.replace('.', '. ')\n",
    "    text = re.sub('[^a-zA-Z.]', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    text = text.strip()\n",
    "\n",
    "    with open('./data/stopword_tala_sastrawi.txt', 'r') as f:\n",
    "        stopword_tala_sastrawi = [line.strip() for line in f]\n",
    "\n",
    "    dictionary = ArrayDictionary(stopword_tala_sastrawi)\n",
    "    str = StopWordRemover(dictionary)\n",
    "    text = str.remove(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/dataset_ekstraksi_r27.xlsx', sheet_name='dataset')\n",
    "df['judul'] = df['judul'].astype(str) + \" \"\n",
    "df = df[\"judul\"] + df[\"isi\"]\n",
    "df = df.apply(preprocess)\n",
    "df = df.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(vocab_len, processed_text, vocabulary):\n",
    "    \"\"\"\n",
    "    Builds a weighted edge graph based on co-occurrences of words in the text.\n",
    "    + perlu ada tambahan formula untuk menghitung score kata yg ada dalam title menjadi lebih besar. (1, 1.5, 2)\n",
    "    \"\"\"\n",
    "    weighted_edge = np.zeros((vocab_len, vocab_len), dtype=np.float32)\n",
    "    score = np.ones((vocab_len), dtype=np.float32)\n",
    "    window_size = 3  \n",
    "    covered_coocurrences = []\n",
    "\n",
    "    for i in range(vocab_len):\n",
    "        for j in range(vocab_len):\n",
    "            if j == i:\n",
    "                weighted_edge[i][j] = 0\n",
    "            else:\n",
    "                for window_start in range(len(processed_text) - window_size):\n",
    "                    window_end = window_start + window_size\n",
    "                    window = processed_text[window_start:window_end]\n",
    "                    if (vocabulary[i] in window) and (vocabulary[j] in window):\n",
    "                        index_of_i = window_start + window.index(vocabulary[i])\n",
    "                        index_of_j = window_start + window.index(vocabulary[j])\n",
    "                        if [index_of_i,index_of_j] not in covered_coocurrences:\n",
    "                            weighted_edge[i][j] += 1 / math.fabs(index_of_i - index_of_j)\n",
    "                            covered_coocurrences.append([index_of_i, index_of_j])\n",
    "\n",
    "    inout = np.sum(weighted_edge, axis=1)\n",
    "  \n",
    "    MAX_ITERATIONS = 50\n",
    "    d = 0.85\n",
    "    threshold = 0.0001\n",
    "    for _ in range(MAX_ITERATIONS):\n",
    "        prev_score = np.copy(score)\n",
    "        for i in range(vocab_len):\n",
    "            summation = 0\n",
    "            for j in range(vocab_len):\n",
    "                if weighted_edge[i][j] != 0:\n",
    "                    summation += (weighted_edge[i][j] / inout[j]) * score[j]\n",
    "            score[i] = (1 - d) + d * summation\n",
    "        if np.sum(np.fabs(prev_score - score)) <= threshold:\n",
    "            break\n",
    "\n",
    "    return vocabulary, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_phrases(unique_phrases, vocabulary, score, multiplier=tuning_multiplier):\n",
    "    \"\"\"\n",
    "    Computes the score of each phrase using the given vocabulary, word scores, and multiplier.\n",
    "    \"\"\"\n",
    "    phrase_scores = []\n",
    "    keywords = []\n",
    "    for phrase in unique_phrases:\n",
    "        phrase_score = 0\n",
    "        keyword = ''\n",
    "        for word in phrase:\n",
    "            keyword += str(word) + \" \"\n",
    "            phrase_score += score[vocabulary.index(word)]\n",
    "        phrase_score *= multiplier\n",
    "        phrase_scores.append(phrase_score)\n",
    "        keywords.append(keyword.strip())\n",
    "\n",
    "    return keywords, phrase_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_phrase(corpus, n=n_top_phrase):  #perlu ada improvement karena phrase yg di hasilkan masih blm proper\n",
    "    vec1 = CountVectorizer(ngram_range=(2,3),  \n",
    "            max_features=2000).fit([corpus])\n",
    "    bag_of_words = vec1.transform([corpus])\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n",
    "                  vec1.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                reverse=True)\n",
    "    # perlu di buat filter jika pola tidak mengikuti kaidah kata majemuk indonesia di excludekan.\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_keywords(text, m=5, f_phrase=5, tuning_multiplier=1):\n",
    "    \"\"\"\n",
    "    Predicts the top m keywords and top f_phrase phrases for the given text.\n",
    "    processed_text = text keseluruhan\n",
    "    vocabulary = unique word dalam proccesesed_text\n",
    "    \"\"\"\n",
    "    processed_text = word_tokenize(text)\n",
    "    vocabulary = list(set(processed_text))\n",
    "    vocab_len = len(vocabulary)\n",
    "    vocabulary, score = build_graph(vocab_len, processed_text, vocabulary)\n",
    "    unigram = pd.DataFrame({\n",
    "        'Keyword': vocabulary,\n",
    "        'Score': score\n",
    "    }).nlargest(m, 'Score')\n",
    "    \n",
    "    bi_trigram = pd.DataFrame(get_top_phrase(text, n=50), columns=['Phrase', 'Score'])\n",
    "    bi_trigram = bi_trigram[bi_trigram['Score'] >= f_phrase]\n",
    "    bi_trigram['Tokens'] = bi_trigram['Phrase'].apply(word_tokenize)\n",
    "    unique_phrases = bi_trigram['Tokens'].values.tolist()\n",
    "    keywords, phrase_scores = score_phrases(unique_phrases, vocabulary, score, tuning_multiplier) #BUG_1 not accesed by pylance, krn tidak di gunakan di procss selanjutnya\n",
    "    # memasukan score ke dalam dataframe\n",
    "    bi_trigram = pd.DataFrame({\n",
    "        'Phrase': keywords,\n",
    "        'Score': phrase_scores\n",
    "    }).nlargest(m, 'Score')\n",
    "\n",
    "      # Combine unigram and bi_trigram dataframes\n",
    "    predict_keywords = pd.concat([unigram, bi_trigram[['Phrase', 'Score']].rename(columns={'Phrase': 'Keyword'})])\\\n",
    "                    .sort_values('Score', ascending=False)\\\n",
    "                    .nlargest(m, 'Score')\\\n",
    "                    .reset_index(drop=True)\n",
    "\n",
    "    return predict_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def write_excel(df, sheet_name, filename):\n",
    "    \"\"\"\n",
    "    Writes the given dataframe to an excel file with the given filename and sheet name.\n",
    "    If the sheet already exists in the file, the data in the sheet will be overwritten.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        book = load_workbook(filename)  # Load the existing workbook\n",
    "    except FileNotFoundError:\n",
    "        book = Workbook()  # If the file doesn't exist, create a new workbook\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "    writer.book = book\n",
    "    \n",
    "    if sheet_name in book.sheetnames:  # If sheet already exists, delete it\n",
    "        idx = book.sheetnames.index(sheet_name)\n",
    "        sheet = book[sheet_name]\n",
    "        book.remove(sheet)\n",
    "        writer.sheets = {ws.title:ws for ws in book.worksheets}\n",
    "        \n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict keywords for all sentences in the dataframe and save the in dataframe\n",
    "predict_textrank = pd.DataFrame()\n",
    "for i in df.index:\n",
    "    keyphrase = predict_keywords(df[i], m_prediksi, tuning_f_phrase, tuning_multiplier).reset_index(drop=True)\n",
    "    a = pd.DataFrame(keyphrase.Keyword).T.reset_index(drop=True)\n",
    "    b = pd.DataFrame(keyphrase.Score).round(2).T.reset_index(drop=True)\n",
    "    keyphrase = pd.concat([a, b], axis=1)\n",
    "    #keyphrase.columns = ['key_1', 'key_2','key_3','score_1', 'score_2','score_3'] \n",
    "\n",
    "    predict_textrank = pd.concat([predict_textrank, keyphrase], ignore_index=True)\n",
    "predict_textrank.columns = ['key_1', 'key_2','key_3','score_1', 'score_2','score_3'] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.f_evaluation import check_similarity, eval\n",
    "\n",
    "df = pd.read_excel('data/dataset_ekstraksi_r27.xlsx', sheet_name='dataset')\n",
    "targets = df[[\"k1\", \"k2\", \"k3\",\"k4\", \"k5\", \"k6\",\"k7\"]].values.tolist()\n",
    "df_targets = pd.DataFrame(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      key_1       key_2     key_3  flex_recall  flex_prec\n",
       "0  no_match    no_match  no_match        0.000      0.000\n",
       "1  no_match  full_match  no_match        0.143      0.333\n",
       "2  no_match    no_match  no_match        0.000      0.000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation TextRank\n",
    "predict_textrank_list = predict_textrank[['key_1','key_2','key_3']].values.tolist()\n",
    "eval_textrank = eval(predict_textrank_list, targets, True).round(3)\n",
    "eval_textrank.columns = ['key_1', 'key_2','key_3','strict_recall', 'strict_prec', 'flex_recall','flex_prec']\n",
    "eval_textrank = eval_textrank[['key_1', 'key_2','key_3', 'flex_recall','flex_prec']] # untuk menyederhanakan hasil evaluasi\n",
    "eval_textrank.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           textrank\n",
       "recall        0.083\n",
       "precision     0.193\n",
       "F1            0.116"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TextRank Score, using flexible score : exact maatch =1, partial match = 1, no match = 0\n",
    "textrank_recall = eval_textrank['flex_recall'].mean()\n",
    "textrank_prec = eval_textrank['flex_prec'].mean()\n",
    "textrank_f1 = 2 * (textrank_prec * textrank_recall) / (textrank_prec + textrank_recall)\n",
    "\n",
    "# Create a DataFrame with the scores\n",
    "summary = pd.DataFrame({'textrank': [textrank_recall, textrank_prec, textrank_f1]}, index=['recall', 'precision', 'F1'])\n",
    "summary = summary.round(3)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>flex_recall</th>\n",
       "      <th>flex_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>personil diajukan fase</td>\n",
       "      <td>diajukan fase tender</td>\n",
       "      <td>personil diajukan</td>\n",
       "      <td>9.55</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7.15</td>\n",
       "      <td>persetujuan tertulis</td>\n",
       "      <td>prosedur</td>\n",
       "      <td>usulan</td>\n",
       "      <td>pengganti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtb</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>gpf</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.55</td>\n",
       "      <td>template document</td>\n",
       "      <td>exhibit c</td>\n",
       "      <td>acuan</td>\n",
       "      <td>pengelolaan</td>\n",
       "      <td>dokumen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>full_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scope of work</td>\n",
       "      <td>ruangan kantor</td>\n",
       "      <td>of work</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.75</td>\n",
       "      <td>ruang kantor</td>\n",
       "      <td>change inquiry</td>\n",
       "      <td>lingkup kerja</td>\n",
       "      <td>akomodasi</td>\n",
       "      <td>services for company</td>\n",
       "      <td>exhibit a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>no_match</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key_1                 key_2              key_3  score_1  \\\n",
       "0  personil diajukan fase  diajukan fase tender  personil diajukan     9.55   \n",
       "1                     jtb               dokumen                gpf     2.25   \n",
       "2           scope of work        ruangan kantor            of work     5.18   \n",
       "\n",
       "   score_2  score_3                     0               1              2  \\\n",
       "0     7.33     7.15  persetujuan tertulis        prosedur         usulan   \n",
       "1     1.62     1.55     template document       exhibit c          acuan   \n",
       "2     4.36     3.75          ruang kantor  change inquiry  lingkup kerja   \n",
       "\n",
       "             3                     4          5    6     key_1       key_2  \\\n",
       "0    pengganti                   NaN        NaN  NaN  no_match    no_match   \n",
       "1  pengelolaan               dokumen        NaN  NaN  no_match  full_match   \n",
       "2    akomodasi  services for company  exhibit a  NaN  no_match    no_match   \n",
       "\n",
       "      key_3  flex_recall  flex_prec  \n",
       "0  no_match        0.000      0.000  \n",
       "1  no_match        0.143      0.333  \n",
       "2  no_match        0.000      0.000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframe predict_textrank, df_targets and eval_textrank\n",
    "predict_textrank = pd.concat([predict_textrank, df_targets, eval_textrank], axis=1)\n",
    "predict_textrank.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to excel file\n",
    "sheet_name = 'tr_phrase'\n",
    "output_file = 'result/02_phrase_prediction.xlsx'\n",
    "write_excel(predict_textrank, sheet_name, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
